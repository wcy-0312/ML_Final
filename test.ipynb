{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc  # Garbage collection for memory management\n",
    "import os  # Operating system-related functions\n",
    "import time  # Time-related functions\n",
    "import warnings  # Handling warnings\n",
    "from itertools import combinations  # For creating combinations of elements\n",
    "from warnings import simplefilter  # Simplifying warning handling\n",
    "\n",
    "# ðŸ“¦ Importing machine learning libraries\n",
    "import joblib  # For saving and loading models\n",
    "import lightgbm as lgb  # LightGBM gradient boosting framework\n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "from sklearn.metrics import mean_absolute_error  # Metric for evaluation\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit  # Cross-validation techniques\n",
    "\n",
    "# ðŸ¤ Disable warnings to keep the code clean\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# ðŸ“Š Define flags and variables\n",
    "is_offline = True  # Flag for online/offline mode\n",
    "is_train = True  # Flag for training mode\n",
    "is_infer = True  # Flag for inference mode\n",
    "max_lookback = np.nan  # Maximum lookback (not specified)\n",
    "split_day = 477  # Split day for time series data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(a):\n",
    "    w = []\n",
    "    n = len(a)\n",
    "    for j in range(1, n + 1):\n",
    "        j = 2 if j == 1 else j\n",
    "        w.append(1 / (2**(n + 1 - j)))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“‚ Read the dataset from a CSV file using Pandas\n",
    "df = pd.read_csv(\"optiver-trading-at-the-close/train.csv\")\n",
    "\n",
    "# ðŸ§¹ Remove rows with missing values in the \"target\" column\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "\n",
    "# ðŸ” Reset the index of the DataFrame and apply the changes in place\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ðŸ“ Get the shape of the DataFrame (number of rows and columns)\n",
    "df_shape = df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§¹ Function to reduce memory usage of a Pandas DataFrame\n",
    "def reduce_mem_usage(df, verbose=0):\n",
    "    \"\"\"\n",
    "    Iterate through all numeric columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ðŸ“ Calculate the initial memory usage of the DataFrame\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    # ðŸ”„ Iterate through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        # Check if the column's data type is not 'object' (i.e., numeric)\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            # Check if the column's data type is an integer\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                # Check if the column's data type is a float\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    # â„¹ï¸ Provide memory optimization information if 'verbose' is True\n",
    "    if verbose:\n",
    "        logger.info(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        logger.info(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        logger.info(f\"Decreased by {decrease:.2f}%\")\n",
    "\n",
    "    # ðŸ”„ Return the DataFrame with optimized memory usage\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽï¸ Import Numba for just-in-time (JIT) compilation and parallel processing\n",
    "from numba import njit, prange\n",
    "\n",
    "# ðŸ“Š Function to compute triplet imbalance in parallel using Numba\n",
    "@njit(parallel=True)\n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "\n",
    "    # ðŸ” Loop through all combinations of triplets\n",
    "    for i in prange(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "        \n",
    "        # ðŸ” Loop through rows of the DataFrame\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "            \n",
    "            # ðŸš« Prevent division by zero\n",
    "            if mid_val == min_val:\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "    return imbalance_features\n",
    "\n",
    "# ðŸ“ˆ Function to calculate triplet imbalance for given price data and a DataFrame\n",
    "def calculate_triplet_imbalance_numba(price, df):\n",
    "    # Convert DataFrame to numpy array for Numba compatibility\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "\n",
    "    # Calculate the triplet imbalance using the Numba-optimized function\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Function to generate imbalance features\n",
    "def imbalance_features(df):\n",
    "    # Define lists of price and size-related column names\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "\n",
    "    # V1 features\n",
    "    # Calculate various features using Pandas eval function\n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "    \n",
    "    # Create features for pairwise price imbalances\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    # Calculate triplet imbalance features using the Numba-optimized function\n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "        \n",
    "    # V2 features\n",
    "    # Calculate additional features\n",
    "    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "    \n",
    "    # Calculate various statistical aggregation features\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "        \n",
    "    # V3 features\n",
    "    # Calculate shifted and return features for specific columns\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window)\n",
    "    \n",
    "    # Calculate diff features for specific columns\n",
    "    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window)\n",
    "\n",
    "    # Replace infinite values with 0\n",
    "    return df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# ðŸ“… Function to generate time and stock-related features\n",
    "def other_features(df):\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5  # Day of the week\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
    "\n",
    "    # Map global features to the DataFrame\n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "\n",
    "    return df\n",
    "\n",
    "# ðŸš€ Function to generate all features by combining imbalance and other features\n",
    "def generate_all_features(df):\n",
    "    # Select relevant columns for feature generation\n",
    "    cols = [c for c in df.columns if c not in [\"row_id\", \"time_id\", \"target\"]]\n",
    "    df = df[cols]\n",
    "    \n",
    "    # Generate imbalance features\n",
    "    df = imbalance_features(df)\n",
    "    \n",
    "    # Generate time and stock-related features\n",
    "    df = other_features(df)\n",
    "    gc.collect()  # Perform garbage collection to free up memory\n",
    "    \n",
    "    # Select and return the generated features\n",
    "    feature_name = [i for i in df.columns if i not in [\"row_id\", \"target\", \"time_id\", \"date_id\"]]\n",
    "    \n",
    "    return df[feature_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offline mode\n",
      "train : (5204892, 17), valid : (33000, 17)\n"
     ]
    }
   ],
   "source": [
    "# Check if the code is running in offline or online mode\n",
    "if is_offline:\n",
    "    # In offline mode, split the data into training and validation sets based on the split_day\n",
    "    df_train = df[df[\"date_id\"] <= split_day]\n",
    "    df_valid = df[df[\"date_id\"] > split_day]\n",
    "    \n",
    "    # Display a message indicating offline mode and the shapes of the training and validation sets\n",
    "    print(\"Offline mode\")\n",
    "    print(f\"train : {df_train.shape}, valid : {df_valid.shape}\")\n",
    "else:\n",
    "    # In online mode, use the entire dataset for training\n",
    "    df_train = df\n",
    "    \n",
    "    # Display a message indicating online mode\n",
    "    print(\"Online mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Train Feats Finished.\n",
      "Build Valid Feats Finished.\n"
     ]
    }
   ],
   "source": [
    "if is_train:\n",
    "    global_stock_id_feats = {\n",
    "        \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "        \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "        \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "        \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "        \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "        \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "    }\n",
    "    if is_offline:\n",
    "        df_train_feats = generate_all_features(df_train)\n",
    "        print(\"Build Train Feats Finished.\")\n",
    "        df_valid_feats = generate_all_features(df_valid)\n",
    "        print(\"Build Valid Feats Finished.\")\n",
    "        df_valid_feats = reduce_mem_usage(df_valid_feats)\n",
    "    else:\n",
    "        df_train_feats = generate_all_features(df_train)\n",
    "        print(\"Build Online Train Feats Finished.\")\n",
    "\n",
    "    df_train_feats = reduce_mem_usage(df_train_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_size_diff_10</th>\n",
       "      <th>dow</th>\n",
       "      <th>seconds</th>\n",
       "      <th>minute</th>\n",
       "      <th>global_median_size</th>\n",
       "      <th>global_std_size</th>\n",
       "      <th>global_ptp_size</th>\n",
       "      <th>global_median_price</th>\n",
       "      <th>global_std_price</th>\n",
       "      <th>global_ptp_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5204892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.753452e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>11548975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>22940.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42514.429688</td>\n",
       "      <td>133007.187500</td>\n",
       "      <td>5.898990e+06</td>\n",
       "      <td>1.999694</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.017414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204893</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.859771e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000245</td>\n",
       "      <td>3850034.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>1967.900024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25425.230469</td>\n",
       "      <td>66472.632812</td>\n",
       "      <td>6.938986e+05</td>\n",
       "      <td>1.999824</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.029370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204894</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.991288e+05</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000584</td>\n",
       "      <td>4359198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>4488.220215</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26191.439453</td>\n",
       "      <td>75695.539062</td>\n",
       "      <td>1.069838e+06</td>\n",
       "      <td>2.000186</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>0.051622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204895</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.872318e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>27129552.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>16082.040039</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41571.328125</td>\n",
       "      <td>93742.078125</td>\n",
       "      <td>1.928848e+06</td>\n",
       "      <td>1.999975</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.018551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204896</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.400591e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>8880891.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>19012.349609</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33945.644531</td>\n",
       "      <td>80624.093750</td>\n",
       "      <td>1.604066e+06</td>\n",
       "      <td>1.999810</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.017379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237887</th>\n",
       "      <td>195</td>\n",
       "      <td>540</td>\n",
       "      <td>2.440723e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>28280362.0</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>32257.039062</td>\n",
       "      <td>...</td>\n",
       "      <td>-10632.959961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>51842.683594</td>\n",
       "      <td>98047.703125</td>\n",
       "      <td>2.761659e+06</td>\n",
       "      <td>1.999925</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.014076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237888</th>\n",
       "      <td>196</td>\n",
       "      <td>540</td>\n",
       "      <td>3.495105e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>9187699.0</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>1.000386</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>205108.406250</td>\n",
       "      <td>...</td>\n",
       "      <td>88602.898438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42405.390625</td>\n",
       "      <td>77778.429688</td>\n",
       "      <td>4.596574e+05</td>\n",
       "      <td>2.000034</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.017398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237889</th>\n",
       "      <td>197</td>\n",
       "      <td>540</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>12725436.0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>16790.660156</td>\n",
       "      <td>...</td>\n",
       "      <td>-20942.289062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>30036.484375</td>\n",
       "      <td>71971.367188</td>\n",
       "      <td>1.575294e+06</td>\n",
       "      <td>1.999968</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.020387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237890</th>\n",
       "      <td>198</td>\n",
       "      <td>540</td>\n",
       "      <td>1.000899e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>94773272.0</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>125631.718750</td>\n",
       "      <td>...</td>\n",
       "      <td>-129903.843750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>304471.000000</td>\n",
       "      <td>354803.406250</td>\n",
       "      <td>2.159163e+06</td>\n",
       "      <td>1.999921</td>\n",
       "      <td>0.003148</td>\n",
       "      <td>0.015738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237891</th>\n",
       "      <td>199</td>\n",
       "      <td>540</td>\n",
       "      <td>1.884286e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>24073678.0</td>\n",
       "      <td>1.000859</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>250081.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>73748.492188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>113987.867188</td>\n",
       "      <td>194455.734375</td>\n",
       "      <td>4.564502e+06</td>\n",
       "      <td>2.000108</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.022793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id  seconds_in_bucket  imbalance_size  imbalance_buy_sell_flag  \\\n",
       "5204892         0                  0    3.753452e+06                       -1   \n",
       "5204893         1                  0    9.859771e+05                       -1   \n",
       "5204894         2                  0    5.991288e+05                        1   \n",
       "5204895         3                  0    2.872318e+06                       -1   \n",
       "5204896         4                  0    7.400591e+05                       -1   \n",
       "...           ...                ...             ...                      ...   \n",
       "5237887       195                540    2.440723e+06                       -1   \n",
       "5237888       196                540    3.495105e+05                       -1   \n",
       "5237889       197                540    0.000000e+00                        0   \n",
       "5237890       198                540    1.000899e+06                        1   \n",
       "5237891       199                540    1.884286e+06                       -1   \n",
       "\n",
       "         reference_price  matched_size  far_price  near_price  bid_price  \\\n",
       "5204892         0.999875    11548975.0        NaN         NaN   0.999875   \n",
       "5204893         1.000245     3850034.0        NaN         NaN   0.999940   \n",
       "5204894         1.000584     4359198.0        NaN         NaN   0.999918   \n",
       "5204895         0.999802    27129552.0        NaN         NaN   0.999705   \n",
       "5204896         0.999886     8880891.0        NaN         NaN   0.999720   \n",
       "...                  ...           ...        ...         ...        ...   \n",
       "5237887         1.000317    28280362.0   0.999734    0.999734   1.000317   \n",
       "5237888         1.000643     9187699.0   1.000129    1.000386   1.000643   \n",
       "5237889         0.995789    12725436.0   0.995789    0.995789   0.995789   \n",
       "5237890         0.999210    94773272.0   0.999210    0.999210   0.998970   \n",
       "5237891         1.002129    24073678.0   1.000859    1.001494   1.002129   \n",
       "\n",
       "              bid_size  ...  bid_size_diff_10  dow  seconds  minute  \\\n",
       "5204892   22940.000000  ...               NaN    3        0       0   \n",
       "5204893    1967.900024  ...               NaN    3        0       0   \n",
       "5204894    4488.220215  ...               NaN    3        0       0   \n",
       "5204895   16082.040039  ...               NaN    3        0       0   \n",
       "5204896   19012.349609  ...               NaN    3        0       0   \n",
       "...                ...  ...               ...  ...      ...     ...   \n",
       "5237887   32257.039062  ...     -10632.959961    0        0       9   \n",
       "5237888  205108.406250  ...      88602.898438    0        0       9   \n",
       "5237889   16790.660156  ...     -20942.289062    0        0       9   \n",
       "5237890  125631.718750  ...    -129903.843750    0        0       9   \n",
       "5237891  250081.437500  ...      73748.492188    0        0       9   \n",
       "\n",
       "         global_median_size  global_std_size  global_ptp_size  \\\n",
       "5204892        42514.429688    133007.187500     5.898990e+06   \n",
       "5204893        25425.230469     66472.632812     6.938986e+05   \n",
       "5204894        26191.439453     75695.539062     1.069838e+06   \n",
       "5204895        41571.328125     93742.078125     1.928848e+06   \n",
       "5204896        33945.644531     80624.093750     1.604066e+06   \n",
       "...                     ...              ...              ...   \n",
       "5237887        51842.683594     98047.703125     2.761659e+06   \n",
       "5237888        42405.390625     77778.429688     4.596574e+05   \n",
       "5237889        30036.484375     71971.367188     1.575294e+06   \n",
       "5237890       304471.000000    354803.406250     2.159163e+06   \n",
       "5237891       113987.867188    194455.734375     4.564502e+06   \n",
       "\n",
       "         global_median_price  global_std_price  global_ptp_price  \n",
       "5204892             1.999694          0.003361          0.017414  \n",
       "5204893             1.999824          0.005599          0.029370  \n",
       "5204894             2.000186          0.005342          0.051622  \n",
       "5204895             1.999975          0.002911          0.018551  \n",
       "5204896             1.999810          0.003727          0.017379  \n",
       "...                      ...               ...               ...  \n",
       "5237887             1.999925          0.003057          0.014076  \n",
       "5237888             2.000034          0.003425          0.017398  \n",
       "5237889             1.999968          0.004696          0.020387  \n",
       "5237890             1.999921          0.003148          0.015738  \n",
       "5237891             2.000108          0.004331          0.022793  \n",
       "\n",
       "[33000 rows x 112 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "lgb_path = ['ensemble_lgb/doblez_1.txt', 'ensemble_lgb/doblez_2.txt', 'ensemble_lgb/doblez_3.txt', 'ensemble_lgb/doblez_4.txt',\n",
    "              'ensemble_lgb/doblez_5.txt', 'ensemble_lgb/doblez-conjunto.txt']\n",
    "\n",
    "lgb_models = [lgb.Booster(model_file=model_filename) for model_filename in lgb_path]\n",
    "\n",
    "xgb_path = ['ensemble_xgb/doblez_1.txt', 'ensemble_xgb/doblez_2.txt', 'ensemble_xgb/doblez_3.txt', 'ensemble_xgb/doblez_4.txt',\n",
    "              'ensemble_xgb/doblez_5.txt', 'ensemble_xgb/doblez-conjunto.txt']\n",
    "\n",
    "xgb_models = [xgb.Booster(model_file=model_filename) for model_filename in xgb_path]\n",
    "\n",
    "cat_path = ['ensemble_cat/doblez_1.cbm', 'ensemble_cat/doblez_2.cbm', 'ensemble_cat/doblez_3.cbm', 'ensemble_cat/doblez_4.cbm',\n",
    "              'ensemble_cat/doblez_5.cbm', 'ensemble_cat/doblez-conjunto.txt']\n",
    "\n",
    "cat_models = [cb.CatBoostRegressor().load_model(model_filename) for model_filename in cat_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices) / np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "    return out\n",
    "\n",
    "\n",
    "def predict(pred_models):\n",
    "    y_min, y_max = -64, 64\n",
    "\n",
    "    # Weights for each fold model\n",
    "    model_weights = [1/len(pred_models)] * len(pred_models) \n",
    "\n",
    "    # Generate predictions for each model and calculate the weighted average\n",
    "    predictions = np.zeros(len(df_valid))\n",
    "    for model, weight in zip(pred_models, model_weights):\n",
    "        predictions += weight * model.predict(df_valid_feats)\n",
    "\n",
    "    predictions = zero_sum(predictions, df_valid['bid_size'] + df_valid['ask_size'])\n",
    "    predictions = np.clip(predictions, y_min, y_max)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM and optimize ensemble weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM score: 5.180033128821017\n"
     ]
    }
   ],
   "source": [
    "lgb_predictions = predict(lgb_models)\n",
    "lgb_score = mean_absolute_error(lgb_predictions, df_valid['target'])\n",
    "\n",
    "print(f'LightGBM score: {lgb_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weight:  [1.26102329e-02 7.15351012e-01 2.72038755e-01 2.02381119e-17\n",
      " 0.00000000e+00 4.58983371e-17]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def objective_function(weights):\n",
    "    y_min, y_max = -64, 64\n",
    "\n",
    "    # Weights for each fold model\n",
    "    # model_weights = [1/len(pred_models)] * len(pred_models) \n",
    "\n",
    "    # Generate predictions for each model and calculate the weighted average\n",
    "    predictions = np.zeros(len(df_valid))\n",
    "    for model, weight in zip(lgb_models, weights):\n",
    "        predictions += weight * model.predict(df_valid_feats)\n",
    "\n",
    "    predictions = zero_sum(predictions, df_valid['bid_size'] + df_valid['ask_size'])\n",
    "    predictions = np.clip(predictions, y_min, y_max)\n",
    "    score = mean_absolute_error(predictions, df_valid['target'])\n",
    "    return score\n",
    "\n",
    "\n",
    "def find_weight():\n",
    "    model_len = len(lgb_models)\n",
    "    initial_weight = np.ones(model_len)/model_len\n",
    "    bounds = [(0, 1)] * model_len\n",
    "    result = minimize(objective_function, initial_weight, bounds=bounds, method='SLSQP')\n",
    "    optimized_weights = result.x\n",
    "    optimized_weights /= np.sum(optimized_weights)\n",
    "    return optimized_weights\n",
    "\n",
    "best_weight = find_weight()\n",
    "\n",
    "print(f'Optimized weight: ', best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_min, y_max = -64, 64\n",
    "\n",
    "# Generate predictions for each model and calculate the weighted average\n",
    "predictions = np.zeros(len(df_valid))\n",
    "for model, weight in zip(lgb_models, best_weight):\n",
    "    predictions += weight * model.predict(df_valid_feats)\n",
    "\n",
    "predictions = zero_sum(predictions, df_valid['bid_size'] + df_valid['ask_size'])\n",
    "predictions = np.clip(predictions, y_min, y_max)\n",
    "score = mean_absolute_error(predictions, df_valid['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.174559202103116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
