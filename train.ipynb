{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/miniconda3/envs/DM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc  # Garbage collection for memory management\n",
    "import os  # Operating system-related functions\n",
    "import time  # Time-related functions\n",
    "import warnings  # Handling warnings\n",
    "from itertools import combinations  # For creating combinations of elements\n",
    "from warnings import simplefilter  # Simplifying warning handling\n",
    "\n",
    "# 📦 Importing machine learning libraries\n",
    "import joblib  # For saving and loading models\n",
    "import lightgbm as lgb  # LightGBM gradient boosting framework\n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "from sklearn.metrics import mean_absolute_error  # Metric for evaluation\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit  # Cross-validation techniques\n",
    "\n",
    "# 🤐 Disable warnings to keep the code clean\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# 📊 Define flags and variables\n",
    "is_offline = True  # Flag for online/offline mode\n",
    "is_train = True  # Flag for training mode\n",
    "is_infer = True  # Flag for inference mode\n",
    "max_lookback = np.nan  # Maximum lookback (not specified)\n",
    "split_day = 477  # Split day for time series data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Data Loading and Preprocessing 📊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 Read the dataset from a CSV file using Pandas\n",
    "df = pd.read_csv(\"optiver-trading-at-the-close/train.csv\")\n",
    "\n",
    "# 🧹 Remove rows with missing values in the \"target\" column\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "\n",
    "# 🔁 Reset the index of the DataFrame and apply the changes in place\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 📏 Get the shape of the DataFrame (number of rows and columns)\n",
    "df_shape = df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Memory Optimization Function with Data Type Conversion 🧹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 Function to reduce memory usage of a Pandas DataFrame\n",
    "def reduce_mem_usage(df, verbose=0):\n",
    "    \"\"\"\n",
    "    Iterate through all numeric columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 📏 Calculate the initial memory usage of the DataFrame\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    # 🔄 Iterate through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        # Check if the column's data type is not 'object' (i.e., numeric)\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            # Check if the column's data type is an integer\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                # Check if the column's data type is a float\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    # ℹ️ Provide memory optimization information if 'verbose' is True\n",
    "    if verbose:\n",
    "        logger.info(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        logger.info(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        logger.info(f\"Decreased by {decrease:.2f}%\")\n",
    "\n",
    "    # 🔄 Return the DataFrame with optimized memory usage\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏎️ Import Numba for just-in-time (JIT) compilation and parallel processing\n",
    "from numba import njit, prange\n",
    "\n",
    "# 📊 Function to compute triplet imbalance in parallel using Numba\n",
    "@njit(parallel=True)\n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "\n",
    "    # 🔁 Loop through all combinations of triplets\n",
    "    for i in prange(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "        \n",
    "        # 🔁 Loop through rows of the DataFrame\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "            \n",
    "            # 🚫 Prevent division by zero\n",
    "            if mid_val == min_val:\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "    return imbalance_features\n",
    "\n",
    "# 📈 Function to calculate triplet imbalance for given price data and a DataFrame\n",
    "def calculate_triplet_imbalance_numba(price, df):\n",
    "    # Convert DataFrame to numpy array for Numba compatibility\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "\n",
    "    # Calculate the triplet imbalance using the Numba-optimized function\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Function to generate imbalance features\n",
    "def imbalance_features(df):\n",
    "    # Define lists of price and size-related column names\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "\n",
    "    # V1 features\n",
    "    # Calculate various features using Pandas eval function\n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "    \n",
    "    # Create features for pairwise price imbalances\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    # Calculate triplet imbalance features using the Numba-optimized function\n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "        \n",
    "    # V2 features\n",
    "    # Calculate additional features\n",
    "    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "    \n",
    "    # Calculate various statistical aggregation features\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "        \n",
    "    # V3 features\n",
    "    # Calculate shifted and return features for specific columns\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window)\n",
    "    \n",
    "    # Calculate diff features for specific columns\n",
    "    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window)\n",
    "\n",
    "    # Replace infinite values with 0\n",
    "    return df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# 📅 Function to generate time and stock-related features\n",
    "def other_features(df):\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5  # Day of the week\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
    "\n",
    "    # Map global features to the DataFrame\n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "\n",
    "    return df\n",
    "\n",
    "# 🚀 Function to generate all features by combining imbalance and other features\n",
    "def generate_all_features(df):\n",
    "    # Select relevant columns for feature generation\n",
    "    cols = [c for c in df.columns if c not in [\"row_id\", \"time_id\", \"target\"]]\n",
    "    df = df[cols]\n",
    "    \n",
    "    # Generate imbalance features\n",
    "    df = imbalance_features(df)\n",
    "    \n",
    "    # Generate time and stock-related features\n",
    "    df = other_features(df)\n",
    "    gc.collect()  # Perform garbage collection to free up memory\n",
    "    \n",
    "    # Select and return the generated features\n",
    "    feature_name = [i for i in df.columns if i not in [\"row_id\", \"target\", \"time_id\", \"date_id\"]]\n",
    "    \n",
    "    return df[feature_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]\n",
    "\n",
    "weights = {int(k):v for k,v in enumerate(weights)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offline mode\n",
      "train : (5204892, 17), valid : (33000, 17)\n"
     ]
    }
   ],
   "source": [
    "# In offline mode, split the data into training and validation sets based on the split_day\n",
    "df_train = df[df[\"date_id\"] <= split_day]\n",
    "df_valid = df[df[\"date_id\"] > split_day]\n",
    "\n",
    "# Display a message indicating offline mode and the shapes of the training and validation sets\n",
    "print(\"Offline mode\")\n",
    "print(f\"train : {df_train.shape}, valid : {df_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Train Feats Finished.\n",
      "Build Valid Feats Finished.\n"
     ]
    }
   ],
   "source": [
    "global_stock_id_feats = {\n",
    "    \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "    \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "    \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "    \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "    \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "    \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "}\n",
    "\n",
    "df_train_feats = generate_all_features(df_train)\n",
    "print(\"Build Train Feats Finished.\")\n",
    "df_valid_feats = generate_all_features(df_valid)\n",
    "print(\"Build Valid Feats Finished.\")\n",
    "df_valid_feats = reduce_mem_usage(df_valid_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Strategy 📊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature length = 112\n",
      "Fold 1 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 5.60875\n",
      "[200]\tvalid_0's l1: 5.57862\n",
      "[300]\tvalid_0's l1: 5.56612\n",
      "[400]\tvalid_0's l1: 5.55781\n",
      "[500]\tvalid_0's l1: 5.55293\n",
      "[600]\tvalid_0's l1: 5.54946\n",
      "[700]\tvalid_0's l1: 5.54697\n",
      "[800]\tvalid_0's l1: 5.54533\n",
      "[900]\tvalid_0's l1: 5.54431\n",
      "[1000]\tvalid_0's l1: 5.54356\n",
      "[1100]\tvalid_0's l1: 5.54301\n",
      "[1200]\tvalid_0's l1: 5.54246\n",
      "[1300]\tvalid_0's l1: 5.54225\n",
      "[1400]\tvalid_0's l1: 5.54192\n",
      "[1500]\tvalid_0's l1: 5.54165\n",
      "[1600]\tvalid_0's l1: 5.54144\n",
      "[1700]\tvalid_0's l1: 5.54128\n",
      "[1800]\tvalid_0's l1: 5.541\n",
      "[1900]\tvalid_0's l1: 5.54078\n",
      "[2000]\tvalid_0's l1: 5.54063\n",
      "[2100]\tvalid_0's l1: 5.54049\n",
      "[2200]\tvalid_0's l1: 5.54031\n",
      "[2300]\tvalid_0's l1: 5.54018\n",
      "[2400]\tvalid_0's l1: 5.54014\n",
      "[2500]\tvalid_0's l1: 5.53999\n",
      "[2600]\tvalid_0's l1: 5.53978\n",
      "[2700]\tvalid_0's l1: 5.53974\n",
      "[2800]\tvalid_0's l1: 5.53964\n",
      "[2900]\tvalid_0's l1: 5.53954\n",
      "[3000]\tvalid_0's l1: 5.53955\n",
      "Early stopping, best iteration is:\n",
      "[2916]\tvalid_0's l1: 5.53952\n",
      "[0]\tvalidation_0-rmse:8.62081\n",
      "[100]\tvalidation_0-rmse:8.48637\n",
      "[200]\tvalidation_0-rmse:8.45173\n",
      "[300]\tvalidation_0-rmse:8.43647\n",
      "[400]\tvalidation_0-rmse:8.42524\n",
      "[500]\tvalidation_0-rmse:8.41854\n",
      "[600]\tvalidation_0-rmse:8.41318\n",
      "[700]\tvalidation_0-rmse:8.40820\n",
      "[800]\tvalidation_0-rmse:8.40395\n",
      "[900]\tvalidation_0-rmse:8.40024\n",
      "[1000]\tvalidation_0-rmse:8.39703\n",
      "[1100]\tvalidation_0-rmse:8.39480\n",
      "[1200]\tvalidation_0-rmse:8.39282\n",
      "[1300]\tvalidation_0-rmse:8.39066\n",
      "[1400]\tvalidation_0-rmse:8.38920\n",
      "[1500]\tvalidation_0-rmse:8.38739\n",
      "[1600]\tvalidation_0-rmse:8.38621\n",
      "[1700]\tvalidation_0-rmse:8.38512\n",
      "[1800]\tvalidation_0-rmse:8.38426\n",
      "[1900]\tvalidation_0-rmse:8.38322\n",
      "[2000]\tvalidation_0-rmse:8.38254\n",
      "[2100]\tvalidation_0-rmse:8.38197\n",
      "[2200]\tvalidation_0-rmse:8.38125\n",
      "[2300]\tvalidation_0-rmse:8.38067\n",
      "[2400]\tvalidation_0-rmse:8.38021\n",
      "[2500]\tvalidation_0-rmse:8.37976\n",
      "[2600]\tvalidation_0-rmse:8.37953\n",
      "[2700]\tvalidation_0-rmse:8.37880\n",
      "[2800]\tvalidation_0-rmse:8.37816\n",
      "[2900]\tvalidation_0-rmse:8.37775\n",
      "[3000]\tvalidation_0-rmse:8.37778\n",
      "[3100]\tvalidation_0-rmse:8.37751\n",
      "[3200]\tvalidation_0-rmse:8.37756\n",
      "[3211]\tvalidation_0-rmse:8.37754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6.5532847\ttest: 5.7210310\tbest: 5.7210310 (0)\ttotal: 14ms\tremaining: 1m 10s\n",
      "100:\tlearn: 6.5461134\ttest: 5.7127732\tbest: 5.7127732 (100)\ttotal: 1.36s\tremaining: 1m 5s\n",
      "200:\tlearn: 6.5395023\ttest: 5.7051515\tbest: 5.7051515 (200)\ttotal: 2.69s\tremaining: 1m 4s\n",
      "300:\tlearn: 6.5333853\ttest: 5.6981032\tbest: 5.6981032 (300)\ttotal: 4.02s\tremaining: 1m 2s\n",
      "400:\tlearn: 6.5276724\ttest: 5.6915379\tbest: 5.6915379 (400)\ttotal: 5.4s\tremaining: 1m 1s\n",
      "500:\tlearn: 6.5223789\ttest: 5.6854254\tbest: 5.6854254 (500)\ttotal: 6.75s\tremaining: 1m\n",
      "600:\tlearn: 6.5174648\ttest: 5.6797400\tbest: 5.6797400 (600)\ttotal: 8.1s\tremaining: 59.3s\n",
      "700:\tlearn: 6.5128598\ttest: 5.6744501\tbest: 5.6744501 (700)\ttotal: 9.46s\tremaining: 58s\n",
      "800:\tlearn: 6.5085917\ttest: 5.6695006\tbest: 5.6695006 (800)\ttotal: 10.9s\tremaining: 57s\n",
      "900:\tlearn: 6.5045825\ttest: 5.6648737\tbest: 5.6648737 (900)\ttotal: 12.3s\tremaining: 55.8s\n",
      "1000:\tlearn: 6.5008501\ttest: 5.6605547\tbest: 5.6605547 (1000)\ttotal: 13.6s\tremaining: 54.5s\n",
      "1100:\tlearn: 6.4973370\ttest: 5.6565113\tbest: 5.6565113 (1100)\ttotal: 15s\tremaining: 53.2s\n",
      "1200:\tlearn: 6.4940466\ttest: 5.6527358\tbest: 5.6527358 (1200)\ttotal: 16.5s\tremaining: 52.2s\n",
      "1300:\tlearn: 6.4909607\ttest: 5.6492157\tbest: 5.6492157 (1300)\ttotal: 17.9s\tremaining: 50.8s\n",
      "1400:\tlearn: 6.4880685\ttest: 5.6459156\tbest: 5.6459156 (1400)\ttotal: 19.3s\tremaining: 49.5s\n",
      "1500:\tlearn: 6.4853712\ttest: 5.6428276\tbest: 5.6428276 (1500)\ttotal: 20.7s\tremaining: 48.3s\n",
      "1600:\tlearn: 6.4828329\ttest: 5.6399354\tbest: 5.6399354 (1600)\ttotal: 22.1s\tremaining: 47s\n",
      "1700:\tlearn: 6.4804306\ttest: 5.6372220\tbest: 5.6372220 (1700)\ttotal: 23.5s\tremaining: 45.6s\n",
      "1800:\tlearn: 6.4781661\ttest: 5.6346610\tbest: 5.6346610 (1800)\ttotal: 24.9s\tremaining: 44.1s\n",
      "1900:\tlearn: 6.4760449\ttest: 5.6322468\tbest: 5.6322468 (1900)\ttotal: 26.3s\tremaining: 42.8s\n",
      "2000:\tlearn: 6.4740427\ttest: 5.6299732\tbest: 5.6299732 (2000)\ttotal: 27.6s\tremaining: 41.4s\n",
      "2100:\tlearn: 6.4721475\ttest: 5.6278264\tbest: 5.6278264 (2100)\ttotal: 29s\tremaining: 40s\n",
      "2200:\tlearn: 6.4703599\ttest: 5.6258052\tbest: 5.6258052 (2200)\ttotal: 30.4s\tremaining: 38.6s\n",
      "2300:\tlearn: 6.4686831\ttest: 5.6238999\tbest: 5.6238999 (2300)\ttotal: 31.8s\tremaining: 37.3s\n",
      "2400:\tlearn: 6.4670690\ttest: 5.6221085\tbest: 5.6221085 (2400)\ttotal: 33.1s\tremaining: 35.9s\n",
      "2500:\tlearn: 6.4655601\ttest: 5.6204164\tbest: 5.6204164 (2500)\ttotal: 34.5s\tremaining: 34.5s\n",
      "2600:\tlearn: 6.4641379\ttest: 5.6188073\tbest: 5.6188073 (2600)\ttotal: 35.9s\tremaining: 33.1s\n",
      "2700:\tlearn: 6.4627851\ttest: 5.6173002\tbest: 5.6173002 (2700)\ttotal: 37.3s\tremaining: 31.7s\n",
      "2800:\tlearn: 6.4614872\ttest: 5.6158615\tbest: 5.6158615 (2800)\ttotal: 38.6s\tremaining: 30.3s\n",
      "2900:\tlearn: 6.4602564\ttest: 5.6145089\tbest: 5.6145089 (2900)\ttotal: 40s\tremaining: 28.9s\n",
      "3000:\tlearn: 6.4590897\ttest: 5.6132068\tbest: 5.6132068 (3000)\ttotal: 41.4s\tremaining: 27.6s\n",
      "3100:\tlearn: 6.4579756\ttest: 5.6119680\tbest: 5.6119680 (3100)\ttotal: 42.8s\tremaining: 26.2s\n",
      "3200:\tlearn: 6.4568971\ttest: 5.6107942\tbest: 5.6107942 (3200)\ttotal: 44.2s\tremaining: 24.8s\n",
      "3300:\tlearn: 6.4558736\ttest: 5.6096733\tbest: 5.6096733 (3300)\ttotal: 45.5s\tremaining: 23.4s\n",
      "3400:\tlearn: 6.4548954\ttest: 5.6086329\tbest: 5.6086329 (3400)\ttotal: 46.9s\tremaining: 22.1s\n",
      "3500:\tlearn: 6.4539428\ttest: 5.6076007\tbest: 5.6076007 (3500)\ttotal: 48.3s\tremaining: 20.7s\n",
      "3600:\tlearn: 6.4530384\ttest: 5.6066441\tbest: 5.6066441 (3600)\ttotal: 49.7s\tremaining: 19.3s\n",
      "3700:\tlearn: 6.4521754\ttest: 5.6057108\tbest: 5.6057108 (3700)\ttotal: 51.1s\tremaining: 17.9s\n",
      "3800:\tlearn: 6.4512999\ttest: 5.6047945\tbest: 5.6047945 (3800)\ttotal: 52.5s\tremaining: 16.6s\n",
      "3900:\tlearn: 6.4504900\ttest: 5.6039348\tbest: 5.6039348 (3900)\ttotal: 53.9s\tremaining: 15.2s\n",
      "4000:\tlearn: 6.4497258\ttest: 5.6031225\tbest: 5.6031225 (4000)\ttotal: 55.3s\tremaining: 13.8s\n",
      "4100:\tlearn: 6.4489578\ttest: 5.6023324\tbest: 5.6023324 (4100)\ttotal: 56.6s\tremaining: 12.4s\n",
      "4200:\tlearn: 6.4482034\ttest: 5.6015587\tbest: 5.6015587 (4200)\ttotal: 58.1s\tremaining: 11s\n",
      "4300:\tlearn: 6.4474937\ttest: 5.6008052\tbest: 5.6008052 (4300)\ttotal: 59.5s\tremaining: 9.67s\n",
      "4400:\tlearn: 6.4467956\ttest: 5.6000902\tbest: 5.6000902 (4400)\ttotal: 1m\tremaining: 8.29s\n",
      "4500:\tlearn: 6.4461274\ttest: 5.5994083\tbest: 5.5994083 (4500)\ttotal: 1m 2s\tremaining: 6.92s\n",
      "4600:\tlearn: 6.4454611\ttest: 5.5987464\tbest: 5.5987464 (4600)\ttotal: 1m 3s\tremaining: 5.54s\n",
      "4700:\tlearn: 6.4448151\ttest: 5.5980948\tbest: 5.5980948 (4700)\ttotal: 1m 5s\tremaining: 4.15s\n",
      "4800:\tlearn: 6.4441821\ttest: 5.5974566\tbest: 5.5974566 (4800)\ttotal: 1m 6s\tremaining: 2.77s\n",
      "4900:\tlearn: 6.4435776\ttest: 5.5968365\tbest: 5.5968365 (4900)\ttotal: 1m 8s\tremaining: 1.38s\n",
      "4999:\tlearn: 6.4429754\ttest: 5.5962519\tbest: 5.5962519 (4999)\ttotal: 1m 9s\tremaining: 0us\n",
      "bestTest = 5.59625185\n",
      "bestIteration = 4999\n",
      "LightGBM for fold 1 saved to ensemble_lgb/doblez_1.txt\n",
      "Xgboost for fold 1 saved to ensemble_xgb/doblez_1.txt\n",
      "Catboost for fold 1 saved to ensemble_cat/doblez_1.cbm\n",
      "Fold 1 MAE: 5.54975639367131\n",
      "Fold 2 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 7.01328\n",
      "[200]\tvalid_0's l1: 6.975\n",
      "[300]\tvalid_0's l1: 6.95831\n",
      "[400]\tvalid_0's l1: 6.94774\n",
      "[500]\tvalid_0's l1: 6.94062\n",
      "[600]\tvalid_0's l1: 6.9357\n",
      "[700]\tvalid_0's l1: 6.93232\n",
      "[800]\tvalid_0's l1: 6.92986\n",
      "[900]\tvalid_0's l1: 6.92836\n",
      "[1000]\tvalid_0's l1: 6.92701\n",
      "[1100]\tvalid_0's l1: 6.92624\n",
      "[1200]\tvalid_0's l1: 6.92563\n",
      "[1300]\tvalid_0's l1: 6.92502\n",
      "[1400]\tvalid_0's l1: 6.92468\n",
      "[1500]\tvalid_0's l1: 6.92416\n",
      "[1600]\tvalid_0's l1: 6.92365\n",
      "[1700]\tvalid_0's l1: 6.92324\n",
      "[1800]\tvalid_0's l1: 6.92291\n",
      "[1900]\tvalid_0's l1: 6.92247\n",
      "[2000]\tvalid_0's l1: 6.92214\n",
      "[2100]\tvalid_0's l1: 6.92181\n",
      "[2200]\tvalid_0's l1: 6.92148\n",
      "[2300]\tvalid_0's l1: 6.92122\n",
      "[2400]\tvalid_0's l1: 6.92094\n",
      "[2500]\tvalid_0's l1: 6.92074\n",
      "[2600]\tvalid_0's l1: 6.92055\n",
      "[2700]\tvalid_0's l1: 6.92037\n",
      "[2800]\tvalid_0's l1: 6.92006\n",
      "[2900]\tvalid_0's l1: 6.91988\n",
      "[3000]\tvalid_0's l1: 6.91966\n",
      "[3100]\tvalid_0's l1: 6.91945\n",
      "[3200]\tvalid_0's l1: 6.91932\n",
      "[3300]\tvalid_0's l1: 6.91924\n",
      "[3400]\tvalid_0's l1: 6.91902\n",
      "[3500]\tvalid_0's l1: 6.91891\n",
      "[3600]\tvalid_0's l1: 6.91883\n",
      "[3700]\tvalid_0's l1: 6.91858\n",
      "[3800]\tvalid_0's l1: 6.91845\n",
      "[3900]\tvalid_0's l1: 6.91827\n",
      "[4000]\tvalid_0's l1: 6.91818\n",
      "[4100]\tvalid_0's l1: 6.91802\n",
      "[4200]\tvalid_0's l1: 6.91795\n",
      "[4300]\tvalid_0's l1: 6.91782\n",
      "[4400]\tvalid_0's l1: 6.91771\n",
      "[4500]\tvalid_0's l1: 6.91765\n",
      "[4600]\tvalid_0's l1: 6.91757\n",
      "[4700]\tvalid_0's l1: 6.91756\n",
      "Early stopping, best iteration is:\n",
      "[4642]\tvalid_0's l1: 6.91752\n",
      "[0]\tvalidation_0-rmse:10.20780\n",
      "[100]\tvalidation_0-rmse:10.05178\n",
      "[200]\tvalidation_0-rmse:10.01059\n",
      "[300]\tvalidation_0-rmse:9.99287\n",
      "[400]\tvalidation_0-rmse:9.98174\n",
      "[500]\tvalidation_0-rmse:9.97451\n",
      "[600]\tvalidation_0-rmse:9.96782\n",
      "[700]\tvalidation_0-rmse:9.96287\n",
      "[800]\tvalidation_0-rmse:9.95765\n",
      "[900]\tvalidation_0-rmse:9.95358\n",
      "[1000]\tvalidation_0-rmse:9.95067\n",
      "[1100]\tvalidation_0-rmse:9.94788\n",
      "[1200]\tvalidation_0-rmse:9.94531\n",
      "[1300]\tvalidation_0-rmse:9.94308\n",
      "[1400]\tvalidation_0-rmse:9.94108\n",
      "[1500]\tvalidation_0-rmse:9.93941\n",
      "[1600]\tvalidation_0-rmse:9.93818\n",
      "[1700]\tvalidation_0-rmse:9.93672\n",
      "[1800]\tvalidation_0-rmse:9.93562\n",
      "[1900]\tvalidation_0-rmse:9.93458\n",
      "[2000]\tvalidation_0-rmse:9.93352\n",
      "[2100]\tvalidation_0-rmse:9.93265\n",
      "[2200]\tvalidation_0-rmse:9.93177\n",
      "[2300]\tvalidation_0-rmse:9.93114\n",
      "[2400]\tvalidation_0-rmse:9.93034\n",
      "[2500]\tvalidation_0-rmse:9.92980\n",
      "[2600]\tvalidation_0-rmse:9.92949\n",
      "[2700]\tvalidation_0-rmse:9.92894\n",
      "[2800]\tvalidation_0-rmse:9.92850\n",
      "[2900]\tvalidation_0-rmse:9.92780\n",
      "[3000]\tvalidation_0-rmse:9.92741\n",
      "[3100]\tvalidation_0-rmse:9.92729\n",
      "[3200]\tvalidation_0-rmse:9.92718\n",
      "[3300]\tvalidation_0-rmse:9.92690\n",
      "[3400]\tvalidation_0-rmse:9.92636\n",
      "[3500]\tvalidation_0-rmse:9.92605\n",
      "[3600]\tvalidation_0-rmse:9.92589\n",
      "[3700]\tvalidation_0-rmse:9.92572\n",
      "[3800]\tvalidation_0-rmse:9.92555\n",
      "[3900]\tvalidation_0-rmse:9.92535\n",
      "[4000]\tvalidation_0-rmse:9.92514\n",
      "[4100]\tvalidation_0-rmse:9.92494\n",
      "[4200]\tvalidation_0-rmse:9.92480\n",
      "[4300]\tvalidation_0-rmse:9.92452\n",
      "[4400]\tvalidation_0-rmse:9.92435\n",
      "[4500]\tvalidation_0-rmse:9.92412\n",
      "[4600]\tvalidation_0-rmse:9.92420\n",
      "[4700]\tvalidation_0-rmse:9.92409\n",
      "[4800]\tvalidation_0-rmse:9.92411\n",
      "[4900]\tvalidation_0-rmse:9.92381\n",
      "[4999]\tvalidation_0-rmse:9.92366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6.1763583\ttest: 7.1436647\tbest: 7.1436647 (0)\ttotal: 14.2ms\tremaining: 1m 11s\n",
      "100:\tlearn: 6.1692258\ttest: 7.1343001\tbest: 7.1343001 (100)\ttotal: 1.34s\tremaining: 1m 5s\n",
      "200:\tlearn: 6.1626816\ttest: 7.1255808\tbest: 7.1255808 (200)\ttotal: 2.69s\tremaining: 1m 4s\n",
      "300:\tlearn: 6.1566456\ttest: 7.1174311\tbest: 7.1174311 (300)\ttotal: 4.03s\tremaining: 1m 2s\n",
      "400:\tlearn: 6.1510480\ttest: 7.1098451\tbest: 7.1098451 (400)\ttotal: 5.41s\tremaining: 1m 1s\n",
      "500:\tlearn: 6.1458728\ttest: 7.1026966\tbest: 7.1026966 (500)\ttotal: 6.75s\tremaining: 1m\n",
      "600:\tlearn: 6.1410738\ttest: 7.0960666\tbest: 7.0960666 (600)\ttotal: 8.1s\tremaining: 59.3s\n",
      "700:\tlearn: 6.1366296\ttest: 7.0898827\tbest: 7.0898827 (700)\ttotal: 9.49s\tremaining: 58.2s\n",
      "800:\tlearn: 6.1325095\ttest: 7.0840566\tbest: 7.0840566 (800)\ttotal: 10.9s\tremaining: 57.1s\n",
      "900:\tlearn: 6.1286600\ttest: 7.0786193\tbest: 7.0786193 (900)\ttotal: 12.3s\tremaining: 55.8s\n",
      "1000:\tlearn: 6.1250908\ttest: 7.0735231\tbest: 7.0735231 (1000)\ttotal: 13.6s\tremaining: 54.4s\n",
      "1100:\tlearn: 6.1217601\ttest: 7.0687407\tbest: 7.0687407 (1100)\ttotal: 15s\tremaining: 53.2s\n",
      "1200:\tlearn: 6.1186732\ttest: 7.0642299\tbest: 7.0642299 (1200)\ttotal: 16.4s\tremaining: 52s\n",
      "1300:\tlearn: 6.1157605\ttest: 7.0600117\tbest: 7.0600117 (1300)\ttotal: 17.8s\tremaining: 50.7s\n",
      "1400:\tlearn: 6.1130746\ttest: 7.0560514\tbest: 7.0560514 (1400)\ttotal: 19.2s\tremaining: 49.3s\n",
      "1500:\tlearn: 6.1105474\ttest: 7.0523329\tbest: 7.0523329 (1500)\ttotal: 20.6s\tremaining: 48s\n",
      "1600:\tlearn: 6.1081939\ttest: 7.0488055\tbest: 7.0488055 (1600)\ttotal: 22s\tremaining: 46.6s\n",
      "1700:\tlearn: 6.1059664\ttest: 7.0454621\tbest: 7.0454621 (1700)\ttotal: 23.3s\tremaining: 45.3s\n",
      "1800:\tlearn: 6.1038923\ttest: 7.0423129\tbest: 7.0423129 (1800)\ttotal: 24.7s\tremaining: 43.9s\n",
      "1900:\tlearn: 6.1019369\ttest: 7.0393248\tbest: 7.0393248 (1900)\ttotal: 26.1s\tremaining: 42.6s\n",
      "2000:\tlearn: 6.1000944\ttest: 7.0365111\tbest: 7.0365111 (2000)\ttotal: 27.5s\tremaining: 41.2s\n",
      "2100:\tlearn: 6.0983657\ttest: 7.0338500\tbest: 7.0338500 (2100)\ttotal: 28.9s\tremaining: 39.8s\n",
      "2200:\tlearn: 6.0967291\ttest: 7.0313273\tbest: 7.0313273 (2200)\ttotal: 30.2s\tremaining: 38.4s\n",
      "2300:\tlearn: 6.0951942\ttest: 7.0289444\tbest: 7.0289444 (2300)\ttotal: 31.6s\tremaining: 37.1s\n",
      "2400:\tlearn: 6.0937517\ttest: 7.0266929\tbest: 7.0266929 (2400)\ttotal: 33s\tremaining: 35.7s\n",
      "2500:\tlearn: 6.0923788\ttest: 7.0245599\tbest: 7.0245599 (2500)\ttotal: 34.4s\tremaining: 34.3s\n",
      "2600:\tlearn: 6.0910872\ttest: 7.0225410\tbest: 7.0225410 (2600)\ttotal: 35.7s\tremaining: 32.9s\n",
      "2700:\tlearn: 6.0898555\ttest: 7.0205936\tbest: 7.0205936 (2700)\ttotal: 37.1s\tremaining: 31.6s\n",
      "2800:\tlearn: 6.0886724\ttest: 7.0187566\tbest: 7.0187566 (2800)\ttotal: 38.5s\tremaining: 30.2s\n",
      "2900:\tlearn: 6.0875404\ttest: 7.0170140\tbest: 7.0170140 (2900)\ttotal: 39.9s\tremaining: 28.8s\n",
      "3000:\tlearn: 6.0864897\ttest: 7.0153524\tbest: 7.0153524 (3000)\ttotal: 41.3s\tremaining: 27.5s\n",
      "3100:\tlearn: 6.0854706\ttest: 7.0137679\tbest: 7.0137679 (3100)\ttotal: 42.6s\tremaining: 26.1s\n",
      "3200:\tlearn: 6.0845070\ttest: 7.0122751\tbest: 7.0122751 (3200)\ttotal: 44s\tremaining: 24.7s\n",
      "3300:\tlearn: 6.0835644\ttest: 7.0108371\tbest: 7.0108371 (3300)\ttotal: 45.4s\tremaining: 23.4s\n",
      "3400:\tlearn: 6.0826782\ttest: 7.0094548\tbest: 7.0094548 (3400)\ttotal: 46.8s\tremaining: 22s\n",
      "3500:\tlearn: 6.0818109\ttest: 7.0081263\tbest: 7.0081263 (3500)\ttotal: 48.2s\tremaining: 20.7s\n",
      "3600:\tlearn: 6.0809739\ttest: 7.0068703\tbest: 7.0068703 (3600)\ttotal: 49.7s\tremaining: 19.3s\n",
      "3700:\tlearn: 6.0801928\ttest: 7.0056426\tbest: 7.0056426 (3700)\ttotal: 51.1s\tremaining: 17.9s\n",
      "3800:\tlearn: 6.0794263\ttest: 7.0044920\tbest: 7.0044920 (3800)\ttotal: 52.5s\tremaining: 16.6s\n",
      "3900:\tlearn: 6.0787012\ttest: 7.0033789\tbest: 7.0033789 (3900)\ttotal: 53.9s\tremaining: 15.2s\n",
      "4000:\tlearn: 6.0779931\ttest: 7.0022992\tbest: 7.0022992 (4000)\ttotal: 55.3s\tremaining: 13.8s\n",
      "4100:\tlearn: 6.0772908\ttest: 7.0012611\tbest: 7.0012611 (4100)\ttotal: 56.8s\tremaining: 12.5s\n",
      "4200:\tlearn: 6.0766207\ttest: 7.0002469\tbest: 7.0002469 (4200)\ttotal: 58.3s\tremaining: 11.1s\n",
      "4300:\tlearn: 6.0759836\ttest: 6.9992792\tbest: 6.9992792 (4300)\ttotal: 59.7s\tremaining: 9.7s\n",
      "4400:\tlearn: 6.0753680\ttest: 6.9983658\tbest: 6.9983658 (4400)\ttotal: 1m 1s\tremaining: 8.32s\n",
      "4500:\tlearn: 6.0747558\ttest: 6.9974570\tbest: 6.9974570 (4500)\ttotal: 1m 2s\tremaining: 6.94s\n",
      "4600:\tlearn: 6.0741363\ttest: 6.9965649\tbest: 6.9965649 (4600)\ttotal: 1m 4s\tremaining: 5.55s\n",
      "4700:\tlearn: 6.0735513\ttest: 6.9957062\tbest: 6.9957062 (4700)\ttotal: 1m 5s\tremaining: 4.17s\n",
      "4800:\tlearn: 6.0729644\ttest: 6.9948749\tbest: 6.9948749 (4800)\ttotal: 1m 7s\tremaining: 2.78s\n",
      "4900:\tlearn: 6.0723950\ttest: 6.9940675\tbest: 6.9940675 (4900)\ttotal: 1m 8s\tremaining: 1.39s\n",
      "4999:\tlearn: 6.0718606\ttest: 6.9932853\tbest: 6.9932853 (4999)\ttotal: 1m 10s\tremaining: 0us\n",
      "bestTest = 6.993285349\n",
      "bestIteration = 4999\n",
      "LightGBM for fold 2 saved to ensemble_lgb/doblez_2.txt\n",
      "Xgboost for fold 2 saved to ensemble_xgb/doblez_2.txt\n",
      "Catboost for fold 2 saved to ensemble_cat/doblez_2.cbm\n",
      "Fold 2 MAE: 6.932013999356162\n",
      "Fold 3 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 6.35823\n",
      "[200]\tvalid_0's l1: 6.33372\n",
      "[300]\tvalid_0's l1: 6.32304\n",
      "[400]\tvalid_0's l1: 6.31516\n",
      "[500]\tvalid_0's l1: 6.30953\n",
      "[600]\tvalid_0's l1: 6.30596\n",
      "[700]\tvalid_0's l1: 6.30363\n",
      "[800]\tvalid_0's l1: 6.30185\n",
      "[900]\tvalid_0's l1: 6.30051\n",
      "[1000]\tvalid_0's l1: 6.29958\n",
      "[1100]\tvalid_0's l1: 6.29898\n",
      "[1200]\tvalid_0's l1: 6.29851\n",
      "[1300]\tvalid_0's l1: 6.29821\n",
      "[1400]\tvalid_0's l1: 6.29787\n",
      "[1500]\tvalid_0's l1: 6.29748\n",
      "[1600]\tvalid_0's l1: 6.29726\n",
      "[1700]\tvalid_0's l1: 6.29697\n",
      "[1800]\tvalid_0's l1: 6.29682\n",
      "[1900]\tvalid_0's l1: 6.29663\n",
      "[2000]\tvalid_0's l1: 6.2964\n",
      "[2100]\tvalid_0's l1: 6.2961\n",
      "[2200]\tvalid_0's l1: 6.29603\n",
      "[2300]\tvalid_0's l1: 6.29584\n",
      "[2400]\tvalid_0's l1: 6.29566\n",
      "[2500]\tvalid_0's l1: 6.29551\n",
      "[2600]\tvalid_0's l1: 6.29533\n",
      "[2700]\tvalid_0's l1: 6.29526\n",
      "[2800]\tvalid_0's l1: 6.29515\n",
      "[2900]\tvalid_0's l1: 6.29509\n",
      "[3000]\tvalid_0's l1: 6.29502\n",
      "[3100]\tvalid_0's l1: 6.29493\n",
      "[3200]\tvalid_0's l1: 6.29487\n",
      "[3300]\tvalid_0's l1: 6.29488\n",
      "Early stopping, best iteration is:\n",
      "[3257]\tvalid_0's l1: 6.29484\n",
      "[0]\tvalidation_0-rmse:9.38706\n",
      "[100]\tvalidation_0-rmse:9.28523\n",
      "[200]\tvalidation_0-rmse:9.25985\n",
      "[300]\tvalidation_0-rmse:9.24820\n",
      "[400]\tvalidation_0-rmse:9.24070\n",
      "[500]\tvalidation_0-rmse:9.23485\n",
      "[600]\tvalidation_0-rmse:9.22994\n",
      "[700]\tvalidation_0-rmse:9.22597\n",
      "[800]\tvalidation_0-rmse:9.22266\n",
      "[900]\tvalidation_0-rmse:9.21938\n",
      "[1000]\tvalidation_0-rmse:9.21714\n",
      "[1100]\tvalidation_0-rmse:9.21513\n",
      "[1200]\tvalidation_0-rmse:9.21286\n",
      "[1300]\tvalidation_0-rmse:9.21129\n",
      "[1400]\tvalidation_0-rmse:9.20951\n",
      "[1500]\tvalidation_0-rmse:9.20835\n",
      "[1600]\tvalidation_0-rmse:9.20725\n",
      "[1700]\tvalidation_0-rmse:9.20649\n",
      "[1800]\tvalidation_0-rmse:9.20557\n",
      "[1900]\tvalidation_0-rmse:9.20481\n",
      "[2000]\tvalidation_0-rmse:9.20400\n",
      "[2100]\tvalidation_0-rmse:9.20312\n",
      "[2200]\tvalidation_0-rmse:9.20267\n",
      "[2300]\tvalidation_0-rmse:9.20196\n",
      "[2400]\tvalidation_0-rmse:9.20193\n",
      "[2486]\tvalidation_0-rmse:9.20193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6.3730717\ttest: 6.4454254\tbest: 6.4454254 (0)\ttotal: 13.4ms\tremaining: 1m 7s\n",
      "100:\tlearn: 6.3650941\ttest: 6.4387452\tbest: 6.4387452 (100)\ttotal: 1.37s\tremaining: 1m 6s\n",
      "200:\tlearn: 6.3577464\ttest: 6.4326086\tbest: 6.4326086 (200)\ttotal: 2.71s\tremaining: 1m 4s\n",
      "300:\tlearn: 6.3509324\ttest: 6.4269339\tbest: 6.4269339 (300)\ttotal: 4.1s\tremaining: 1m 4s\n",
      "400:\tlearn: 6.3446219\ttest: 6.4216949\tbest: 6.4216949 (400)\ttotal: 5.45s\tremaining: 1m 2s\n",
      "500:\tlearn: 6.3387694\ttest: 6.4168515\tbest: 6.4168515 (500)\ttotal: 6.79s\tremaining: 1m\n",
      "600:\tlearn: 6.3333459\ttest: 6.4123726\tbest: 6.4123726 (600)\ttotal: 8.13s\tremaining: 59.5s\n",
      "700:\tlearn: 6.3282984\ttest: 6.4082194\tbest: 6.4082194 (700)\ttotal: 9.51s\tremaining: 58.3s\n",
      "800:\tlearn: 6.3235842\ttest: 6.4043700\tbest: 6.4043700 (800)\ttotal: 10.9s\tremaining: 56.9s\n",
      "900:\tlearn: 6.3191915\ttest: 6.4007902\tbest: 6.4007902 (900)\ttotal: 12.2s\tremaining: 55.6s\n",
      "1000:\tlearn: 6.3151036\ttest: 6.3974794\tbest: 6.3974794 (1000)\ttotal: 13.6s\tremaining: 54.2s\n",
      "1100:\tlearn: 6.3112881\ttest: 6.3943735\tbest: 6.3943735 (1100)\ttotal: 15s\tremaining: 53s\n",
      "1200:\tlearn: 6.3077164\ttest: 6.3915000\tbest: 6.3915000 (1200)\ttotal: 16.4s\tremaining: 51.8s\n",
      "1300:\tlearn: 6.3043526\ttest: 6.3888283\tbest: 6.3888283 (1300)\ttotal: 17.8s\tremaining: 50.5s\n",
      "1400:\tlearn: 6.3012288\ttest: 6.3863438\tbest: 6.3863438 (1400)\ttotal: 19.2s\tremaining: 49.2s\n",
      "1500:\tlearn: 6.2983299\ttest: 6.3840381\tbest: 6.3840381 (1500)\ttotal: 20.5s\tremaining: 47.9s\n",
      "1600:\tlearn: 6.2955769\ttest: 6.3818905\tbest: 6.3818905 (1600)\ttotal: 21.9s\tremaining: 46.5s\n",
      "1700:\tlearn: 6.2930283\ttest: 6.3798874\tbest: 6.3798874 (1700)\ttotal: 23.3s\tremaining: 45.1s\n",
      "1800:\tlearn: 6.2906353\ttest: 6.3780235\tbest: 6.3780235 (1800)\ttotal: 24.7s\tremaining: 43.8s\n",
      "1900:\tlearn: 6.2883902\ttest: 6.3762926\tbest: 6.3762926 (1900)\ttotal: 26s\tremaining: 42.4s\n",
      "2000:\tlearn: 6.2862567\ttest: 6.3746560\tbest: 6.3746560 (2000)\ttotal: 27.4s\tremaining: 41s\n",
      "2100:\tlearn: 6.2842545\ttest: 6.3731404\tbest: 6.3731404 (2100)\ttotal: 28.7s\tremaining: 39.7s\n",
      "2200:\tlearn: 6.2823880\ttest: 6.3717233\tbest: 6.3717233 (2200)\ttotal: 30.1s\tremaining: 38.3s\n",
      "2300:\tlearn: 6.2806087\ttest: 6.3703819\tbest: 6.3703819 (2300)\ttotal: 31.5s\tremaining: 37s\n",
      "2400:\tlearn: 6.2789261\ttest: 6.3691289\tbest: 6.3691289 (2400)\ttotal: 32.9s\tremaining: 35.6s\n",
      "2500:\tlearn: 6.2773269\ttest: 6.3679386\tbest: 6.3679386 (2500)\ttotal: 34.2s\tremaining: 34.2s\n",
      "2600:\tlearn: 6.2758291\ttest: 6.3668196\tbest: 6.3668196 (2600)\ttotal: 35.6s\tremaining: 32.9s\n",
      "2700:\tlearn: 6.2743894\ttest: 6.3657719\tbest: 6.3657719 (2700)\ttotal: 37s\tremaining: 31.5s\n",
      "2800:\tlearn: 6.2730341\ttest: 6.3647744\tbest: 6.3647744 (2800)\ttotal: 38.4s\tremaining: 30.1s\n",
      "2900:\tlearn: 6.2717315\ttest: 6.3638286\tbest: 6.3638286 (2900)\ttotal: 39.7s\tremaining: 28.8s\n",
      "3000:\tlearn: 6.2704860\ttest: 6.3629245\tbest: 6.3629245 (3000)\ttotal: 41.1s\tremaining: 27.4s\n",
      "3100:\tlearn: 6.2693044\ttest: 6.3620736\tbest: 6.3620736 (3100)\ttotal: 42.5s\tremaining: 26s\n",
      "3200:\tlearn: 6.2681862\ttest: 6.3612659\tbest: 6.3612659 (3200)\ttotal: 43.8s\tremaining: 24.6s\n",
      "3300:\tlearn: 6.2670973\ttest: 6.3604923\tbest: 6.3604923 (3300)\ttotal: 45.2s\tremaining: 23.3s\n",
      "3400:\tlearn: 6.2660450\ttest: 6.3597307\tbest: 6.3597307 (3400)\ttotal: 46.6s\tremaining: 21.9s\n",
      "3500:\tlearn: 6.2650527\ttest: 6.3590103\tbest: 6.3590103 (3500)\ttotal: 48s\tremaining: 20.6s\n",
      "3600:\tlearn: 6.2641096\ttest: 6.3583316\tbest: 6.3583316 (3600)\ttotal: 49.4s\tremaining: 19.2s\n",
      "3700:\tlearn: 6.2631793\ttest: 6.3576509\tbest: 6.3576509 (3700)\ttotal: 50.8s\tremaining: 17.8s\n",
      "3800:\tlearn: 6.2622831\ttest: 6.3570028\tbest: 6.3570028 (3800)\ttotal: 52.2s\tremaining: 16.5s\n",
      "3900:\tlearn: 6.2614410\ttest: 6.3563888\tbest: 6.3563888 (3900)\ttotal: 53.6s\tremaining: 15.1s\n",
      "4000:\tlearn: 6.2606073\ttest: 6.3557950\tbest: 6.3557950 (4000)\ttotal: 55s\tremaining: 13.7s\n",
      "4100:\tlearn: 6.2598257\ttest: 6.3552382\tbest: 6.3552382 (4100)\ttotal: 56.4s\tremaining: 12.4s\n",
      "4200:\tlearn: 6.2590695\ttest: 6.3547121\tbest: 6.3547121 (4200)\ttotal: 57.9s\tremaining: 11s\n",
      "4300:\tlearn: 6.2583206\ttest: 6.3541770\tbest: 6.3541770 (4300)\ttotal: 59.3s\tremaining: 9.63s\n",
      "4400:\tlearn: 6.2575976\ttest: 6.3536499\tbest: 6.3536499 (4400)\ttotal: 1m\tremaining: 8.26s\n",
      "4500:\tlearn: 6.2568927\ttest: 6.3531489\tbest: 6.3531489 (4500)\ttotal: 1m 2s\tremaining: 6.89s\n",
      "4600:\tlearn: 6.2562209\ttest: 6.3526629\tbest: 6.3526629 (4600)\ttotal: 1m 3s\tremaining: 5.51s\n",
      "4700:\tlearn: 6.2555457\ttest: 6.3521730\tbest: 6.3521730 (4700)\ttotal: 1m 5s\tremaining: 4.14s\n",
      "4800:\tlearn: 6.2549012\ttest: 6.3517126\tbest: 6.3517126 (4800)\ttotal: 1m 6s\tremaining: 2.75s\n",
      "4900:\tlearn: 6.2542470\ttest: 6.3512337\tbest: 6.3512337 (4900)\ttotal: 1m 7s\tremaining: 1.37s\n",
      "4999:\tlearn: 6.2536196\ttest: 6.3507769\tbest: 6.3507769 (4999)\ttotal: 1m 9s\tremaining: 0us\n",
      "bestTest = 6.350776861\n",
      "bestIteration = 4999\n",
      "LightGBM for fold 3 saved to ensemble_lgb/doblez_3.txt\n",
      "Xgboost for fold 3 saved to ensemble_xgb/doblez_3.txt\n",
      "Catboost for fold 3 saved to ensemble_cat/doblez_3.cbm\n",
      "Fold 3 MAE: 6.308527175901606\n",
      "Fold 4 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 6.3485\n",
      "[200]\tvalid_0's l1: 6.32441\n",
      "[300]\tvalid_0's l1: 6.31402\n",
      "[400]\tvalid_0's l1: 6.30575\n",
      "[500]\tvalid_0's l1: 6.30051\n",
      "[600]\tvalid_0's l1: 6.29722\n",
      "[700]\tvalid_0's l1: 6.29489\n",
      "[800]\tvalid_0's l1: 6.29307\n",
      "[900]\tvalid_0's l1: 6.29207\n",
      "[1000]\tvalid_0's l1: 6.2913\n",
      "[1100]\tvalid_0's l1: 6.29086\n",
      "[1200]\tvalid_0's l1: 6.29052\n",
      "[1300]\tvalid_0's l1: 6.29013\n",
      "[1400]\tvalid_0's l1: 6.28981\n",
      "[1500]\tvalid_0's l1: 6.28944\n",
      "[1600]\tvalid_0's l1: 6.28912\n",
      "[1700]\tvalid_0's l1: 6.28891\n",
      "[1800]\tvalid_0's l1: 6.28876\n",
      "[1900]\tvalid_0's l1: 6.28865\n",
      "[2000]\tvalid_0's l1: 6.28853\n",
      "[2100]\tvalid_0's l1: 6.28848\n",
      "[2200]\tvalid_0's l1: 6.28832\n",
      "[2300]\tvalid_0's l1: 6.28824\n",
      "[2400]\tvalid_0's l1: 6.28815\n",
      "[2500]\tvalid_0's l1: 6.28809\n",
      "[2600]\tvalid_0's l1: 6.288\n",
      "[2700]\tvalid_0's l1: 6.28791\n",
      "[2800]\tvalid_0's l1: 6.28771\n",
      "[2900]\tvalid_0's l1: 6.28772\n",
      "Early stopping, best iteration is:\n",
      "[2823]\tvalid_0's l1: 6.28769\n",
      "[0]\tvalidation_0-rmse:9.48380\n",
      "[100]\tvalidation_0-rmse:9.38909\n",
      "[200]\tvalidation_0-rmse:9.36415\n",
      "[300]\tvalidation_0-rmse:9.35074\n",
      "[400]\tvalidation_0-rmse:9.34170\n",
      "[500]\tvalidation_0-rmse:9.33465\n",
      "[600]\tvalidation_0-rmse:9.33095\n",
      "[700]\tvalidation_0-rmse:9.32780\n",
      "[800]\tvalidation_0-rmse:9.32429\n",
      "[900]\tvalidation_0-rmse:9.32159\n",
      "[1000]\tvalidation_0-rmse:9.31957\n",
      "[1100]\tvalidation_0-rmse:9.31829\n",
      "[1200]\tvalidation_0-rmse:9.31622\n",
      "[1300]\tvalidation_0-rmse:9.31505\n",
      "[1400]\tvalidation_0-rmse:9.31393\n",
      "[1500]\tvalidation_0-rmse:9.31334\n",
      "[1600]\tvalidation_0-rmse:9.31267\n",
      "[1700]\tvalidation_0-rmse:9.31241\n",
      "[1800]\tvalidation_0-rmse:9.31235\n",
      "[1900]\tvalidation_0-rmse:9.31157\n",
      "[2000]\tvalidation_0-rmse:9.31096\n",
      "[2100]\tvalidation_0-rmse:9.31079\n",
      "[2183]\tvalidation_0-rmse:9.31079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6.4095746\ttest: 6.4333852\tbest: 6.4333852 (0)\ttotal: 13.8ms\tremaining: 1m 8s\n",
      "100:\tlearn: 6.4016063\ttest: 6.4267400\tbest: 6.4267400 (100)\ttotal: 1.33s\tremaining: 1m 4s\n",
      "200:\tlearn: 6.3942602\ttest: 6.4206584\tbest: 6.4206584 (200)\ttotal: 2.64s\tremaining: 1m 2s\n",
      "300:\tlearn: 6.3874466\ttest: 6.4150735\tbest: 6.4150735 (300)\ttotal: 3.95s\tremaining: 1m 1s\n",
      "400:\tlearn: 6.3811253\ttest: 6.4099232\tbest: 6.4099232 (400)\ttotal: 5.32s\tremaining: 1m 1s\n",
      "500:\tlearn: 6.3752520\ttest: 6.4051602\tbest: 6.4051602 (500)\ttotal: 6.65s\tremaining: 59.7s\n",
      "600:\tlearn: 6.3697880\ttest: 6.4007708\tbest: 6.4007708 (600)\ttotal: 7.99s\tremaining: 58.5s\n",
      "700:\tlearn: 6.3646962\ttest: 6.3966988\tbest: 6.3966988 (700)\ttotal: 9.31s\tremaining: 57.1s\n",
      "800:\tlearn: 6.3599786\ttest: 6.3929665\tbest: 6.3929665 (800)\ttotal: 10.7s\tremaining: 56.2s\n",
      "900:\tlearn: 6.3555561\ttest: 6.3894785\tbest: 6.3894785 (900)\ttotal: 12.1s\tremaining: 55s\n",
      "1000:\tlearn: 6.3514451\ttest: 6.3862583\tbest: 6.3862583 (1000)\ttotal: 13.4s\tremaining: 53.7s\n",
      "1100:\tlearn: 6.3476126\ttest: 6.3832580\tbest: 6.3832580 (1100)\ttotal: 14.8s\tremaining: 52.5s\n",
      "1200:\tlearn: 6.3440331\ttest: 6.3804850\tbest: 6.3804850 (1200)\ttotal: 16.2s\tremaining: 51.4s\n",
      "1300:\tlearn: 6.3406857\ttest: 6.3778884\tbest: 6.3778884 (1300)\ttotal: 17.6s\tremaining: 50.1s\n",
      "1400:\tlearn: 6.3375551\ttest: 6.3754886\tbest: 6.3754886 (1400)\ttotal: 19s\tremaining: 48.8s\n",
      "1500:\tlearn: 6.3346213\ttest: 6.3732503\tbest: 6.3732503 (1500)\ttotal: 20.4s\tremaining: 47.5s\n",
      "1600:\tlearn: 6.3318849\ttest: 6.3711468\tbest: 6.3711468 (1600)\ttotal: 21.8s\tremaining: 46.2s\n",
      "1700:\tlearn: 6.3292995\ttest: 6.3691967\tbest: 6.3691967 (1700)\ttotal: 23.1s\tremaining: 44.9s\n",
      "1800:\tlearn: 6.3268870\ttest: 6.3673945\tbest: 6.3673945 (1800)\ttotal: 24.5s\tremaining: 43.5s\n",
      "1900:\tlearn: 6.3246166\ttest: 6.3657237\tbest: 6.3657237 (1900)\ttotal: 25.8s\tremaining: 42.1s\n",
      "2000:\tlearn: 6.3225093\ttest: 6.3641583\tbest: 6.3641583 (2000)\ttotal: 27.2s\tremaining: 40.8s\n",
      "2100:\tlearn: 6.3204934\ttest: 6.3626884\tbest: 6.3626884 (2100)\ttotal: 28.5s\tremaining: 39.4s\n",
      "2200:\tlearn: 6.3186089\ttest: 6.3613084\tbest: 6.3613084 (2200)\ttotal: 29.9s\tremaining: 38s\n",
      "2300:\tlearn: 6.3168294\ttest: 6.3600114\tbest: 6.3600114 (2300)\ttotal: 31.3s\tremaining: 36.7s\n",
      "2400:\tlearn: 6.3151305\ttest: 6.3587967\tbest: 6.3587967 (2400)\ttotal: 32.7s\tremaining: 35.4s\n",
      "2500:\tlearn: 6.3135337\ttest: 6.3576521\tbest: 6.3576521 (2500)\ttotal: 34s\tremaining: 34s\n",
      "2600:\tlearn: 6.3120014\ttest: 6.3565444\tbest: 6.3565444 (2600)\ttotal: 35.4s\tremaining: 32.6s\n",
      "2700:\tlearn: 6.3105556\ttest: 6.3555146\tbest: 6.3555146 (2700)\ttotal: 36.7s\tremaining: 31.3s\n",
      "2800:\tlearn: 6.3091737\ttest: 6.3545298\tbest: 6.3545298 (2800)\ttotal: 38.1s\tremaining: 29.9s\n",
      "2900:\tlearn: 6.3078709\ttest: 6.3536015\tbest: 6.3536015 (2900)\ttotal: 39.5s\tremaining: 28.6s\n",
      "3000:\tlearn: 6.3066297\ttest: 6.3527231\tbest: 6.3527231 (3000)\ttotal: 40.9s\tremaining: 27.2s\n",
      "3100:\tlearn: 6.3054315\ttest: 6.3518707\tbest: 6.3518707 (3100)\ttotal: 42.3s\tremaining: 25.9s\n",
      "3200:\tlearn: 6.3043085\ttest: 6.3510893\tbest: 6.3510893 (3200)\ttotal: 43.7s\tremaining: 24.6s\n",
      "3300:\tlearn: 6.3032227\ttest: 6.3503224\tbest: 6.3503224 (3300)\ttotal: 45s\tremaining: 23.2s\n",
      "3400:\tlearn: 6.3022003\ttest: 6.3496044\tbest: 6.3496044 (3400)\ttotal: 46.4s\tremaining: 21.8s\n",
      "3500:\tlearn: 6.3012112\ttest: 6.3489304\tbest: 6.3489304 (3500)\ttotal: 47.8s\tremaining: 20.5s\n",
      "3600:\tlearn: 6.3002704\ttest: 6.3482863\tbest: 6.3482863 (3600)\ttotal: 49.2s\tremaining: 19.1s\n",
      "3700:\tlearn: 6.2993467\ttest: 6.3476398\tbest: 6.3476398 (3700)\ttotal: 50.6s\tremaining: 17.8s\n",
      "3800:\tlearn: 6.2984601\ttest: 6.3470357\tbest: 6.3470357 (3800)\ttotal: 51.9s\tremaining: 16.4s\n",
      "3900:\tlearn: 6.2976058\ttest: 6.3464487\tbest: 6.3464487 (3900)\ttotal: 53.4s\tremaining: 15s\n",
      "4000:\tlearn: 6.2967529\ttest: 6.3458691\tbest: 6.3458691 (4000)\ttotal: 54.7s\tremaining: 13.7s\n",
      "4100:\tlearn: 6.2959758\ttest: 6.3453230\tbest: 6.3453230 (4100)\ttotal: 56.1s\tremaining: 12.3s\n",
      "4200:\tlearn: 6.2952363\ttest: 6.3448134\tbest: 6.3448134 (4200)\ttotal: 57.5s\tremaining: 10.9s\n",
      "4300:\tlearn: 6.2944816\ttest: 6.3442992\tbest: 6.3442992 (4300)\ttotal: 59s\tremaining: 9.59s\n",
      "4400:\tlearn: 6.2937669\ttest: 6.3438171\tbest: 6.3438171 (4400)\ttotal: 1m\tremaining: 8.22s\n",
      "4500:\tlearn: 6.2930548\ttest: 6.3433194\tbest: 6.3433194 (4500)\ttotal: 1m 1s\tremaining: 6.85s\n",
      "4600:\tlearn: 6.2923904\ttest: 6.3428508\tbest: 6.3428508 (4600)\ttotal: 1m 3s\tremaining: 5.49s\n",
      "4700:\tlearn: 6.2917222\ttest: 6.3424051\tbest: 6.3424051 (4700)\ttotal: 1m 4s\tremaining: 4.12s\n",
      "4800:\tlearn: 6.2910540\ttest: 6.3419504\tbest: 6.3419504 (4800)\ttotal: 1m 6s\tremaining: 2.74s\n",
      "4900:\tlearn: 6.2904288\ttest: 6.3415202\tbest: 6.3415202 (4900)\ttotal: 1m 7s\tremaining: 1.37s\n",
      "4999:\tlearn: 6.2898055\ttest: 6.3411015\tbest: 6.3411015 (4999)\ttotal: 1m 9s\tremaining: 0us\n",
      "bestTest = 6.341101542\n",
      "bestIteration = 4999\n",
      "LightGBM for fold 4 saved to ensemble_lgb/doblez_4.txt\n",
      "Xgboost for fold 4 saved to ensemble_xgb/doblez_4.txt\n",
      "Catboost for fold 4 saved to ensemble_cat/doblez_4.cbm\n",
      "Fold 4 MAE: 6.300287424360699\n",
      "Fold 5 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 5.99615\n",
      "[200]\tvalid_0's l1: 5.97265\n",
      "[300]\tvalid_0's l1: 5.96274\n",
      "[400]\tvalid_0's l1: 5.9555\n",
      "[500]\tvalid_0's l1: 5.95064\n",
      "[600]\tvalid_0's l1: 5.94747\n",
      "[700]\tvalid_0's l1: 5.94569\n",
      "[800]\tvalid_0's l1: 5.94446\n",
      "[900]\tvalid_0's l1: 5.94377\n",
      "[1000]\tvalid_0's l1: 5.94305\n",
      "[1100]\tvalid_0's l1: 5.94245\n",
      "[1200]\tvalid_0's l1: 5.94223\n",
      "[1300]\tvalid_0's l1: 5.94196\n",
      "[1400]\tvalid_0's l1: 5.94164\n",
      "[1500]\tvalid_0's l1: 5.94145\n",
      "[1600]\tvalid_0's l1: 5.94128\n",
      "[1700]\tvalid_0's l1: 5.94108\n",
      "[1800]\tvalid_0's l1: 5.94089\n",
      "[1900]\tvalid_0's l1: 5.94078\n",
      "[2000]\tvalid_0's l1: 5.94069\n",
      "[2100]\tvalid_0's l1: 5.94059\n",
      "[2200]\tvalid_0's l1: 5.94057\n",
      "[2300]\tvalid_0's l1: 5.94047\n",
      "[2400]\tvalid_0's l1: 5.94036\n",
      "[2500]\tvalid_0's l1: 5.94027\n",
      "[2600]\tvalid_0's l1: 5.94028\n",
      "Early stopping, best iteration is:\n",
      "[2510]\tvalid_0's l1: 5.94026\n",
      "[0]\tvalidation_0-rmse:9.03793\n",
      "[100]\tvalidation_0-rmse:8.95120\n",
      "[200]\tvalidation_0-rmse:8.92884\n",
      "[300]\tvalidation_0-rmse:8.91735\n",
      "[400]\tvalidation_0-rmse:8.91082\n",
      "[500]\tvalidation_0-rmse:8.90499\n",
      "[600]\tvalidation_0-rmse:8.90063\n",
      "[700]\tvalidation_0-rmse:8.89751\n",
      "[800]\tvalidation_0-rmse:8.89453\n",
      "[900]\tvalidation_0-rmse:8.89202\n",
      "[1000]\tvalidation_0-rmse:8.89022\n",
      "[1100]\tvalidation_0-rmse:8.88867\n",
      "[1200]\tvalidation_0-rmse:8.88718\n",
      "[1300]\tvalidation_0-rmse:8.88600\n",
      "[1400]\tvalidation_0-rmse:8.88555\n",
      "[1500]\tvalidation_0-rmse:8.88464\n",
      "[1600]\tvalidation_0-rmse:8.88430\n",
      "[1700]\tvalidation_0-rmse:8.88356\n",
      "[1800]\tvalidation_0-rmse:8.88338\n",
      "[1834]\tvalidation_0-rmse:8.88330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6.4948223\ttest: 6.0786163\tbest: 6.0786163 (0)\ttotal: 12.9ms\tremaining: 1m 4s\n",
      "100:\tlearn: 6.4869205\ttest: 6.0721874\tbest: 6.0721874 (100)\ttotal: 1.31s\tremaining: 1m 3s\n",
      "200:\tlearn: 6.4796156\ttest: 6.0662869\tbest: 6.0662869 (200)\ttotal: 2.62s\tremaining: 1m 2s\n",
      "300:\tlearn: 6.4728370\ttest: 6.0608531\tbest: 6.0608531 (300)\ttotal: 3.98s\tremaining: 1m 2s\n",
      "400:\tlearn: 6.4665477\ttest: 6.0558288\tbest: 6.0558288 (400)\ttotal: 5.31s\tremaining: 1m\n",
      "500:\tlearn: 6.4607125\ttest: 6.0512211\tbest: 6.0512211 (500)\ttotal: 6.63s\tremaining: 59.5s\n",
      "600:\tlearn: 6.4552716\ttest: 6.0469452\tbest: 6.0469452 (600)\ttotal: 7.96s\tremaining: 58.3s\n",
      "700:\tlearn: 6.4502071\ttest: 6.0429904\tbest: 6.0429904 (700)\ttotal: 9.35s\tremaining: 57.4s\n",
      "800:\tlearn: 6.4455216\ttest: 6.0393673\tbest: 6.0393673 (800)\ttotal: 10.7s\tremaining: 56.1s\n",
      "900:\tlearn: 6.4411166\ttest: 6.0359695\tbest: 6.0359695 (900)\ttotal: 12.1s\tremaining: 54.9s\n",
      "1000:\tlearn: 6.4370207\ttest: 6.0328315\tbest: 6.0328315 (1000)\ttotal: 13.4s\tremaining: 53.6s\n",
      "1100:\tlearn: 6.4331768\ttest: 6.0299163\tbest: 6.0299163 (1100)\ttotal: 14.9s\tremaining: 52.6s\n",
      "1200:\tlearn: 6.4295966\ttest: 6.0271948\tbest: 6.0271948 (1200)\ttotal: 16.2s\tremaining: 51.3s\n",
      "1300:\tlearn: 6.4262473\ttest: 6.0246647\tbest: 6.0246647 (1300)\ttotal: 17.6s\tremaining: 50s\n",
      "1400:\tlearn: 6.4231294\ttest: 6.0223169\tbest: 6.0223169 (1400)\ttotal: 19s\tremaining: 48.7s\n",
      "1500:\tlearn: 6.4201913\ttest: 6.0201295\tbest: 6.0201295 (1500)\ttotal: 20.4s\tremaining: 47.5s\n",
      "1600:\tlearn: 6.4174306\ttest: 6.0180899\tbest: 6.0180899 (1600)\ttotal: 21.7s\tremaining: 46.2s\n",
      "1700:\tlearn: 6.4148459\ttest: 6.0161927\tbest: 6.0161927 (1700)\ttotal: 23.1s\tremaining: 44.8s\n",
      "1800:\tlearn: 6.4124308\ttest: 6.0144489\tbest: 6.0144489 (1800)\ttotal: 24.5s\tremaining: 43.5s\n",
      "1900:\tlearn: 6.4101589\ttest: 6.0128229\tbest: 6.0128229 (1900)\ttotal: 25.8s\tremaining: 42.1s\n",
      "2000:\tlearn: 6.4080008\ttest: 6.0112863\tbest: 6.0112863 (2000)\ttotal: 27.2s\tremaining: 40.7s\n",
      "2100:\tlearn: 6.4059998\ttest: 6.0098772\tbest: 6.0098772 (2100)\ttotal: 28.5s\tremaining: 39.3s\n",
      "2200:\tlearn: 6.4040938\ttest: 6.0085499\tbest: 6.0085499 (2200)\ttotal: 29.9s\tremaining: 38s\n",
      "2300:\tlearn: 6.4022894\ttest: 6.0073001\tbest: 6.0073001 (2300)\ttotal: 31.3s\tremaining: 36.7s\n",
      "2400:\tlearn: 6.4005782\ttest: 6.0061257\tbest: 6.0061257 (2400)\ttotal: 32.6s\tremaining: 35.3s\n",
      "2500:\tlearn: 6.3989517\ttest: 6.0049918\tbest: 6.0049918 (2500)\ttotal: 34s\tremaining: 34s\n",
      "2600:\tlearn: 6.3974150\ttest: 6.0039183\tbest: 6.0039183 (2600)\ttotal: 35.4s\tremaining: 32.6s\n",
      "2700:\tlearn: 6.3959789\ttest: 6.0029103\tbest: 6.0029103 (2700)\ttotal: 36.8s\tremaining: 31.3s\n",
      "2800:\tlearn: 6.3945805\ttest: 6.0019257\tbest: 6.0019257 (2800)\ttotal: 38.1s\tremaining: 29.9s\n",
      "2900:\tlearn: 6.3932708\ttest: 6.0010070\tbest: 6.0010070 (2900)\ttotal: 39.5s\tremaining: 28.6s\n",
      "3000:\tlearn: 6.3920049\ttest: 6.0001289\tbest: 6.0001289 (3000)\ttotal: 41s\tremaining: 27.3s\n",
      "3100:\tlearn: 6.3907954\ttest: 5.9992737\tbest: 5.9992737 (3100)\ttotal: 42.4s\tremaining: 25.9s\n",
      "3200:\tlearn: 6.3896535\ttest: 5.9984694\tbest: 5.9984694 (3200)\ttotal: 43.8s\tremaining: 24.6s\n",
      "3300:\tlearn: 6.3885496\ttest: 5.9977212\tbest: 5.9977212 (3300)\ttotal: 45.2s\tremaining: 23.2s\n",
      "3400:\tlearn: 6.3874717\ttest: 5.9969893\tbest: 5.9969893 (3400)\ttotal: 46.6s\tremaining: 21.9s\n",
      "3500:\tlearn: 6.3864609\ttest: 5.9962655\tbest: 5.9962655 (3500)\ttotal: 48s\tremaining: 20.6s\n",
      "3600:\tlearn: 6.3854693\ttest: 5.9955722\tbest: 5.9955722 (3600)\ttotal: 49.4s\tremaining: 19.2s\n",
      "3700:\tlearn: 6.3845423\ttest: 5.9949588\tbest: 5.9949588 (3700)\ttotal: 50.8s\tremaining: 17.8s\n",
      "3800:\tlearn: 6.3836370\ttest: 5.9943443\tbest: 5.9943443 (3800)\ttotal: 52.2s\tremaining: 16.5s\n",
      "3900:\tlearn: 6.3827423\ttest: 5.9937309\tbest: 5.9937309 (3900)\ttotal: 53.6s\tremaining: 15.1s\n",
      "4000:\tlearn: 6.3818727\ttest: 5.9931400\tbest: 5.9931400 (4000)\ttotal: 55s\tremaining: 13.7s\n",
      "4100:\tlearn: 6.3810576\ttest: 5.9925930\tbest: 5.9925930 (4100)\ttotal: 56.5s\tremaining: 12.4s\n",
      "4200:\tlearn: 6.3802598\ttest: 5.9920860\tbest: 5.9920860 (4200)\ttotal: 57.9s\tremaining: 11s\n",
      "4300:\tlearn: 6.3795111\ttest: 5.9915964\tbest: 5.9915964 (4300)\ttotal: 59.3s\tremaining: 9.64s\n",
      "4400:\tlearn: 6.3787553\ttest: 5.9911329\tbest: 5.9911329 (4400)\ttotal: 1m\tremaining: 8.27s\n",
      "4500:\tlearn: 6.3780380\ttest: 5.9906578\tbest: 5.9906578 (4500)\ttotal: 1m 2s\tremaining: 6.9s\n",
      "4600:\tlearn: 6.3773424\ttest: 5.9902322\tbest: 5.9902322 (4600)\ttotal: 1m 3s\tremaining: 5.52s\n",
      "4700:\tlearn: 6.3766560\ttest: 5.9897921\tbest: 5.9897921 (4700)\ttotal: 1m 5s\tremaining: 4.14s\n",
      "4800:\tlearn: 6.3759864\ttest: 5.9893695\tbest: 5.9893695 (4800)\ttotal: 1m 6s\tremaining: 2.76s\n",
      "4900:\tlearn: 6.3753139\ttest: 5.9889300\tbest: 5.9889300 (4900)\ttotal: 1m 7s\tremaining: 1.37s\n",
      "4999:\tlearn: 6.3746704\ttest: 5.9885278\tbest: 5.9885278 (4999)\ttotal: 1m 9s\tremaining: 0us\n",
      "bestTest = 5.98852783\n",
      "bestIteration = 4999\n",
      "LightGBM for fold 5 saved to ensemble_lgb/doblez_5.txt\n",
      "Xgboost for fold 5 saved to ensemble_xgb/doblez_5.txt\n",
      "Catboost for fold 5 saved to ensemble_cat/doblez_5.cbm\n",
      "Fold 5 MAE: 5.9515911467813325\n",
      "Training final LightGBM with average best iteration: 3229\n",
      "Training final Xgboost with average best iteration: 2862\n",
      "Training final Catboost with average best iteration: 4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6.4145934\ttotal: 15.5ms\tremaining: 1m 17s\n",
      "100:\tlearn: 6.4069794\ttotal: 1.64s\tremaining: 1m 19s\n",
      "200:\tlearn: 6.3999672\ttotal: 3.31s\tremaining: 1m 19s\n",
      "300:\tlearn: 6.3934610\ttotal: 4.93s\tremaining: 1m 16s\n",
      "400:\tlearn: 6.3874444\ttotal: 6.6s\tremaining: 1m 15s\n",
      "500:\tlearn: 6.3818396\ttotal: 8.22s\tremaining: 1m 13s\n",
      "600:\tlearn: 6.3766564\ttotal: 9.89s\tremaining: 1m 12s\n",
      "700:\tlearn: 6.3718125\ttotal: 11.6s\tremaining: 1m 10s\n",
      "800:\tlearn: 6.3673229\ttotal: 13.2s\tremaining: 1m 9s\n",
      "900:\tlearn: 6.3631161\ttotal: 14.9s\tremaining: 1m 7s\n",
      "1000:\tlearn: 6.3592032\ttotal: 16.6s\tremaining: 1m 6s\n",
      "1100:\tlearn: 6.3555436\ttotal: 18.3s\tremaining: 1m 4s\n",
      "1200:\tlearn: 6.3521164\ttotal: 20s\tremaining: 1m 3s\n",
      "1300:\tlearn: 6.3489202\ttotal: 21.8s\tremaining: 1m 1s\n",
      "1400:\tlearn: 6.3459415\ttotal: 23.5s\tremaining: 1m\n",
      "1500:\tlearn: 6.3431622\ttotal: 25.2s\tremaining: 58.8s\n",
      "1600:\tlearn: 6.3405262\ttotal: 26.9s\tremaining: 57.1s\n",
      "1700:\tlearn: 6.3380773\ttotal: 28.6s\tremaining: 55.5s\n",
      "1800:\tlearn: 6.3357695\ttotal: 30.3s\tremaining: 53.8s\n",
      "1900:\tlearn: 6.3336096\ttotal: 32s\tremaining: 52.1s\n",
      "2000:\tlearn: 6.3315800\ttotal: 33.7s\tremaining: 50.4s\n",
      "2100:\tlearn: 6.3296718\ttotal: 35.3s\tremaining: 48.7s\n",
      "2200:\tlearn: 6.3278792\ttotal: 37s\tremaining: 47.1s\n",
      "2300:\tlearn: 6.3261847\ttotal: 38.6s\tremaining: 45.3s\n",
      "2400:\tlearn: 6.3245808\ttotal: 40.3s\tremaining: 43.6s\n",
      "2500:\tlearn: 6.3230676\ttotal: 41.9s\tremaining: 41.9s\n",
      "2600:\tlearn: 6.3216213\ttotal: 43.6s\tremaining: 40.2s\n",
      "2700:\tlearn: 6.3202537\ttotal: 45.3s\tremaining: 38.5s\n",
      "2800:\tlearn: 6.3189484\ttotal: 46.9s\tremaining: 36.8s\n",
      "2900:\tlearn: 6.3177119\ttotal: 48.6s\tremaining: 35.2s\n",
      "3000:\tlearn: 6.3165115\ttotal: 50.3s\tremaining: 33.5s\n",
      "3100:\tlearn: 6.3153941\ttotal: 52s\tremaining: 31.8s\n",
      "3200:\tlearn: 6.3142962\ttotal: 53.7s\tremaining: 30.2s\n",
      "3300:\tlearn: 6.3132726\ttotal: 55.4s\tremaining: 28.5s\n",
      "3400:\tlearn: 6.3122639\ttotal: 57.1s\tremaining: 26.8s\n",
      "3500:\tlearn: 6.3113421\ttotal: 58.8s\tremaining: 25.2s\n",
      "3600:\tlearn: 6.3104310\ttotal: 1m\tremaining: 23.5s\n",
      "3700:\tlearn: 6.3095177\ttotal: 1m 2s\tremaining: 21.9s\n",
      "3800:\tlearn: 6.3086408\ttotal: 1m 3s\tremaining: 20.2s\n",
      "3900:\tlearn: 6.3078435\ttotal: 1m 5s\tremaining: 18.5s\n",
      "4000:\tlearn: 6.3070431\ttotal: 1m 7s\tremaining: 16.8s\n",
      "4100:\tlearn: 6.3062803\ttotal: 1m 9s\tremaining: 15.2s\n",
      "4200:\tlearn: 6.3055168\ttotal: 1m 10s\tremaining: 13.5s\n",
      "4300:\tlearn: 6.3048190\ttotal: 1m 12s\tremaining: 11.8s\n",
      "4400:\tlearn: 6.3041216\ttotal: 1m 14s\tremaining: 10.1s\n",
      "4500:\tlearn: 6.3034518\ttotal: 1m 16s\tremaining: 8.43s\n",
      "4600:\tlearn: 6.3027848\ttotal: 1m 17s\tremaining: 6.74s\n",
      "4700:\tlearn: 6.3021423\ttotal: 1m 19s\tremaining: 5.05s\n",
      "4800:\tlearn: 6.3015283\ttotal: 1m 21s\tremaining: 3.36s\n",
      "4900:\tlearn: 6.3009330\ttotal: 1m 23s\tremaining: 1.67s\n",
      "4998:\tlearn: 6.3003325\ttotal: 1m 25s\tremaining: 0us\n",
      "Final LightGBM saved to ensemble_lgb/doblez-conjunto.txt\n",
      "Final Xgboost saved to ensemble_xgb/doblez-conjunto.txt\n",
      "Final Catboost saved to ensemble_cat/doblez-conjunto.txt\n",
      "Average MAE across all folds: 6.208435228014222\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "\n",
    "# Assuming df_train_feats and df_train are already defined and df_train contains the 'date_id' column\n",
    "\n",
    "# Set up parameters for LightGBM, Xgboost, Catboost\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"mae\",\n",
    "    \"n_estimators\": 5000,\n",
    "    \"num_leaves\": 256,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"learning_rate\": 0.00871,\n",
    "    \"n_jobs\": 4,\n",
    "    \"device\": \"gpu\",\n",
    "    \"verbosity\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"n_estimators\": 5000,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"learning_rate\": 0.00871,\n",
    "    \"n_jobs\": 4,\n",
    "    \"tree_method\": \"gpu_hist\",  \n",
    "    \"gpu_id\": 0  \n",
    "}\n",
    "\n",
    "cb_params = {\n",
    "    \"loss_function\": \"MAE\",\n",
    "    \"iterations\": 5000,\n",
    "    \"depth\": 8,\n",
    "    \"learning_rate\": 0.00871,\n",
    "    \"bootstrap_type\": \"Bernoulli\",\n",
    "    \"subsample\": 0.6,\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"devices\": \"0\",  # Set the GPU device(s) you want to use\n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "\n",
    "feature_name = list(df_train_feats.columns)\n",
    "print(f\"Feature length = {len(feature_name)}\")\n",
    "\n",
    "# The total number of date_ids is 480, we split them into 5 folds with a gap of 5 days in between\n",
    "num_folds = 5\n",
    "fold_size = 480 // num_folds\n",
    "gap = 5\n",
    "\n",
    "lgb_models = []\n",
    "xgb_models = []\n",
    "cat_models = []\n",
    "\n",
    "scores = []\n",
    "\n",
    "lgb_save_path = 'ensemble_lgb'  # Directory to save models\n",
    "if not os.path.exists(lgb_save_path):\n",
    "    os.makedirs(lgb_save_path)\n",
    "xgb_save_path = 'ensemble_xgb'  # Directory to save models\n",
    "if not os.path.exists(xgb_save_path):\n",
    "    os.makedirs(xgb_save_path)\n",
    "cat_save_path = 'ensemble_cat'  # Directory to save models\n",
    "if not os.path.exists(cat_save_path):\n",
    "    os.makedirs(cat_save_path)\n",
    "\n",
    "# We need to use the date_id from df_train to split the data\n",
    "date_ids = df_train['date_id'].values\n",
    "\n",
    "for i in range(num_folds):\n",
    "    start = i * fold_size\n",
    "    end = start + fold_size\n",
    "    \n",
    "    # Define the purged set ranges\n",
    "    purged_before_start = start - 2\n",
    "    purged_before_end = start + 2\n",
    "    purged_after_start = end - 2\n",
    "    purged_after_end = end + 2\n",
    "    \n",
    "    # Exclude the purged ranges from the test set\n",
    "    purged_set = ((date_ids >= purged_before_start) & (date_ids <= purged_before_end)) | \\\n",
    "                 ((date_ids >= purged_after_start) & (date_ids <= purged_after_end))\n",
    "    \n",
    "    # Define test_indices excluding the purged set\n",
    "    test_indices = (date_ids >= start) & (date_ids < end) & ~purged_set\n",
    "    train_indices = ~test_indices & ~purged_set\n",
    "    \n",
    "    df_fold_train = df_train_feats[train_indices]\n",
    "    df_fold_train_target = df_train['target'][train_indices]\n",
    "    df_fold_valid = df_train_feats[test_indices]\n",
    "    df_fold_valid_target = df_train['target'][test_indices]\n",
    "\n",
    "    print(f\"Fold {i+1} Model Training\")\n",
    "    \n",
    "    # Train models for the current fold\n",
    "    lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    lgb_model.fit(\n",
    "        df_fold_train[feature_name],\n",
    "        df_fold_train_target,\n",
    "        eval_set=[(df_fold_valid[feature_name], df_fold_valid_target)],\n",
    "        callbacks=[\n",
    "            lgb.callback.early_stopping(stopping_rounds=100),\n",
    "            lgb.callback.log_evaluation(period=100),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "    xgb_model.fit(\n",
    "        df_fold_train[feature_name],\n",
    "        df_fold_train_target,\n",
    "        eval_set=[(df_fold_valid[feature_name], df_fold_valid_target)],\n",
    "        early_stopping_rounds=100,  # early stopping\n",
    "        verbose=100,\n",
    "    )\n",
    "\n",
    "    cb_model = cb.CatBoostRegressor(**cb_params)\n",
    "    cb_model.fit(\n",
    "        df_fold_train[feature_name],\n",
    "        df_fold_train_target,\n",
    "        eval_set=(df_fold_valid[feature_name], df_fold_valid_target),\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Append the model to the list\n",
    "    lgb_models.append(lgb_model)\n",
    "    xgb_models.append(xgb_model)\n",
    "    cat_models.append(cb_model)\n",
    "\n",
    "\n",
    "    # Save the model to a file\n",
    "    model_filename = os.path.join(lgb_save_path, f'doblez_{i+1}.txt')\n",
    "    lgb_model.booster_.save_model(model_filename)\n",
    "    print(f\"LightGBM for fold {i+1} saved to {model_filename}\")\n",
    "\n",
    "    model_filename = os.path.join(xgb_save_path, f'doblez_{i+1}.txt')\n",
    "    xgb_model.save_model(model_filename)\n",
    "    print(f\"Xgboost for fold {i+1} saved to {model_filename}\")\n",
    "\n",
    "    model_filename = os.path.join(cat_save_path, f'doblez_{i+1}.cbm')\n",
    "    cb_model.save_model(model_filename)\n",
    "    print(f\"Catboost for fold {i+1} saved to {model_filename}\")\n",
    "\n",
    "    # Evaluate model performance on the validation set\n",
    "    fold_predictions = (lgb_model.predict(df_fold_valid[feature_name]) + xgb_model.predict(df_fold_valid[feature_name]) + cb_model.predict(df_fold_valid[feature_name]))/3\n",
    "    fold_score = mean_absolute_error(fold_predictions, df_fold_valid_target)\n",
    "    scores.append(fold_score)\n",
    "    print(f\"Fold {i+1} MAE: {fold_score}\")\n",
    "\n",
    "    # Free up memory by deleting fold specific variables\n",
    "    del df_fold_train, df_fold_train_target, df_fold_valid, df_fold_valid_target\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate the average best iteration from all regular folds\n",
    "average_best_iteration_lgb = int(np.mean([model.best_iteration_ for model in lgb_models]))\n",
    "average_best_iteration_xgb = int(np.mean([model.best_iteration for model in xgb_models]))\n",
    "average_best_iteration_cat = int(np.mean([model.get_best_iteration() for model in cat_models]))\n",
    "\n",
    "# Update the lgb_params with the average best iteration\n",
    "final_lgb_params = lgb_params.copy()\n",
    "final_lgb_params['n_estimators'] = average_best_iteration_lgb\n",
    "print(f\"Training final LightGBM with average best iteration: {average_best_iteration_lgb}\")\n",
    "\n",
    "final_xgb_params = xgb_params.copy()\n",
    "final_xgb_params['n_estimators'] = average_best_iteration_xgb\n",
    "print(f\"Training final Xgboost with average best iteration: {average_best_iteration_xgb}\")\n",
    "\n",
    "final_cat_params = cb_params.copy()\n",
    "final_cat_params['iterations'] = average_best_iteration_cat\n",
    "print(f\"Training final Catboost with average best iteration: {average_best_iteration_cat}\")\n",
    "\n",
    "# Train the final model on the entire dataset\n",
    "final_lgb = lgb.LGBMRegressor(**final_lgb_params)\n",
    "final_lgb.fit(\n",
    "    df_train_feats[feature_name],\n",
    "    df_train['target'],\n",
    "    callbacks=[\n",
    "        lgb.callback.log_evaluation(period=100),\n",
    "    ],\n",
    ")\n",
    "\n",
    "final_xgb = xgb.XGBRegressor(**final_xgb_params)\n",
    "final_xgb.fit(\n",
    "    df_train_feats[feature_name],\n",
    "    df_train['target'],\n",
    "    verbose=100,\n",
    ")\n",
    "\n",
    "final_cb = cb.CatBoostRegressor(**final_cat_params)\n",
    "final_cb.fit(\n",
    "    df_train_feats[feature_name],\n",
    "    df_train['target'],\n",
    "    verbose_eval=100,\n",
    ")\n",
    "# Append the final model to the list of models\n",
    "lgb_models.append(final_lgb)\n",
    "xgb_models.append(final_xgb)\n",
    "cat_models.append(final_cb)\n",
    "\n",
    "# Save the final model to a file\n",
    "final_model_filename = os.path.join(lgb_save_path, 'doblez-conjunto.txt')\n",
    "final_lgb.booster_.save_model(final_model_filename)\n",
    "print(f\"Final LightGBM saved to {final_model_filename}\")\n",
    "\n",
    "final_model_filename = os.path.join(xgb_save_path, 'doblez-conjunto.txt')\n",
    "final_xgb.save_model(final_model_filename)\n",
    "print(f\"Final Xgboost saved to {final_model_filename}\")\n",
    "\n",
    "final_model_filename = os.path.join(cat_save_path, 'doblez-conjunto.txt')\n",
    "final_cb.save_model(final_model_filename)\n",
    "print(f\"Final Catboost saved to {final_model_filename}\")\n",
    "\n",
    "# Now 'models' holds the trained models for each fold and 'scores' holds the validation scores\n",
    "print(f\"Average MAE across all folds: {np.mean(scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score: 5.192273304789406\n"
     ]
    }
   ],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices) / np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "    return out\n",
    "\n",
    "\n",
    "def predict(pred_models):\n",
    "    y_min, y_max = -64, 64\n",
    "\n",
    "    # Weights for each fold model\n",
    "    model_weights = [1/len(pred_models)] * len(pred_models) \n",
    "\n",
    "    # Generate predictions for each model and calculate the weighted average\n",
    "    predictions = np.zeros(len(df_valid))\n",
    "    for model, weight in zip(pred_models, model_weights):\n",
    "        predictions += weight * model.predict(df_valid_feats)\n",
    "\n",
    "    predictions = zero_sum(predictions, df_valid['bid_size'] + df_valid['ask_size'])\n",
    "    predictions = np.clip(predictions, y_min, y_max)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "ensemble_predictions = (predict(lgb_models) + predict(xgb_models) + predict(cat_models))/3\n",
    "final_score = mean_absolute_error(ensemble_predictions, df_valid['target'])\n",
    "\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score: 5.184976785104516\n"
     ]
    }
   ],
   "source": [
    "weights = [0.6, 0.2, 0.2]\n",
    "\n",
    "ensemble_predictions_1 = np.average([predict(lgb_models), predict(xgb_models), predict(cat_models)], axis=0, weights=weights)\n",
    "final_score_1 = mean_absolute_error(ensemble_predictions_1, df_valid['target'])\n",
    "\n",
    "print(f'Final score: {final_score_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM score: 5.180033128821017\n"
     ]
    }
   ],
   "source": [
    "lgb_predictions = predict(lgb_models)\n",
    "lgb_score = mean_absolute_error(lgb_predictions, df_valid['target'])\n",
    "\n",
    "print(f'LightGBM score: {lgb_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: 5.215549938892475\n"
     ]
    }
   ],
   "source": [
    "xgb_predictions = predict(xgb_models)\n",
    "xgb_score = mean_absolute_error(xgb_predictions, df_valid['target'])\n",
    "\n",
    "print(f'Xgboost score: {xgb_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catboost score: 5.219583261324764\n"
     ]
    }
   ],
   "source": [
    "cat_predictions = predict(cat_models)\n",
    "cat_score = mean_absolute_error(cat_predictions, df_valid['target'])\n",
    "\n",
    "print(f'Catboost score: {cat_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weight:  [9.04947418e-01 7.97515162e-17 9.50525816e-02]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def objective_function(weights):\n",
    "    ensemble_predictions = np.average([predict(lgb_models), predict(xgb_models), predict(cat_models)], axis=0, weights=weights)\n",
    "    score = mean_absolute_error(ensemble_predictions, df_valid['target'])\n",
    "    return score\n",
    "\n",
    "\n",
    "def find_weight():\n",
    "    initial_weight = np.ones(3)/3\n",
    "    bounds = [(0, 1)] * 3\n",
    "    result = minimize(objective_function, initial_weight, bounds=bounds, method='SLSQP')\n",
    "    optimized_weights = result.x\n",
    "    optimized_weights /= np.sum(optimized_weights)\n",
    "    return optimized_weights\n",
    "\n",
    "best_weight = find_weight()\n",
    "\n",
    "print(f'Optimized weight: ', best_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBM + XGB + CAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.179568085464417"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_predictions = np.average([predict(lgb_models), predict(xgb_models), predict(cat_models)], axis=0, weights=best_weight)\n",
    "final_score = mean_absolute_error(ensemble_predictions, df_valid['target'])\n",
    "\n",
    "final_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
